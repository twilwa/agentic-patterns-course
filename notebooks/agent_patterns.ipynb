{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production-Ready Agent Engineering: From MCP to RL\n",
    "\n",
    "### Lecture 1: Agent Patterns and Principles\n",
    "\n",
    "**Instructor: Will Brown**\n",
    "\n",
    "*Date: June 17, 2025*\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "Install [uv](https://docs.astral.sh/uv/getting-started/installation/) (recommended, pip alternative)\n",
    "```bash\n",
    "# mac/linux\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# windows\n",
    "powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n",
    "\n",
    "# or, install via pip\n",
    "pip install uv\n",
    "\n",
    "# to initialize a project:\n",
    "uv init [project-name]\n",
    "uv add openai # creates .venv\n",
    "uv add ipykernel ipywidgets # for jupyter\n",
    "```\n",
    "\n",
    "Set up an LLM API key\n",
    "```bash\n",
    "# terminal or bashrc/zshrc\n",
    "export OPENAI_API_KEY=sk-proj-...\n",
    "```\n",
    "\n",
    "### Choosing Models\n",
    "\n",
    "Recommended \"agent\" models:\n",
    "- DeepSeek V3-0324\n",
    "    - cheap, reliable, solid all around (think Sonnet 3.5 / GPT-4o)\n",
    "    - not a \"reasoner\" by default, but works well with \"\\<think\\>\" prompting (trained on R1 data)\n",
    "    - free + automatic prefix caching via deepseek.ai (don't trust with sensitive data)\n",
    "    - available from many inference providers (Bedrock, Azure Foundry, Together, Fireworks, OpenRouter)\n",
    "    - **no restrictions on distillation/training**\n",
    "- gpt-4.1\n",
    "    - more \"agentic\" / less \"chatty\" alternative to gpt-4o\n",
    "    - good default for \"capable non-reasoner\", particularly if you mostly work with OpenAI models\n",
    "- Claude 4 Sonnet + Gemini 2.5 Pro\n",
    "    - very strong all-around agentic models\n",
    "    - popular in code editors (Cursor, Windsurf, Claude Code)\n",
    "    - configurable thinking budgets\n",
    "\n",
    "Recommended \"helper\" models (or \"mini\" agents):\n",
    "- gpt-4.1-mini / gpt-4.1-nano\n",
    "- Gemini 2.5 Flash\n",
    "- Claude 3.5 Haiku\n",
    "- Mistral Small 3.1 (24B)\n",
    "    - very permissive license\n",
    "    - popular as a finetuning base\n",
    "- Qwen 2.5/3 models\n",
    "    - many variants + sizes\n",
    "    - popular for finetuning + self-hosting\n",
    "    - Qwen3 models are \"thinking optional\"\n",
    "- Gemma 3 models\n",
    "    - mini/open versions of Gemini \n",
    "- Other small open models (for finetuning + simple helper methods)\n",
    "    - Llama 3.1 8B\n",
    "    - Phi-4 (non-reasoning)\n",
    "\n",
    "Sometimes useful, but proceed with caution:\n",
    "- o3, R1, o4-mini\n",
    "    - \"reasoning\" models are generally slow, expensive, prone to overthinking\n",
    "    - often overkill for many tasks, particularly if you require low latency + many tool calls\n",
    "    - o4-mini supports the RFT API for reinforcement learning\n",
    "- Claude 4 Opus\n",
    "    - one of the strongest models ever made, but **very** expensive\n",
    "- Llama 4 (Scout / Maverick)\n",
    "    - winning combo: fast inference *and* multimodal *and* openly available *and* fairly strong\n",
    "    - lots of RAM needed for self-hosting; similar license to Llama models\n",
    "\n",
    "Course logistics:\n",
    "\n",
    "- Thursday lecture on MCP + productionizing agents\n",
    "    - **new time**: 3PM ET\n",
    "    - Also doing a \"repeat\" lecture on Friday at 5PM ET\n",
    "    - Happy to schedule a weekend option \n",
    "- Office hours on Friday at 3pm ET\n",
    "\n",
    "--- \n",
    "\n",
    "### Topics\n",
    "\n",
    "OpenAI Chat Completions\n",
    "\n",
    "OpenAI Responses\n",
    "\n",
    "Tool Calling\n",
    "\n",
    "Structured Outputs\n",
    "- Instructor\n",
    "- Outlines, XGrammar\n",
    "\n",
    "ReAct: Synergizing Reasoning + Acting\n",
    "\n",
    "- PydanticAI\n",
    "- OpenAI Agents SDK\n",
    "- SmolAgents\n",
    "- several others\n",
    "\n",
    "LLM Judges (DeepEval)\n",
    "\n",
    "Stateful Agents (Letta)\n",
    "\n",
    "Signatures + Agent Optimization (DSPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Chat Completions\n",
    "\n",
    "- Will be our default mode of LLM interaction throughout the course\n",
    "- Very flexible, minimal \"bells and whistles\", supported by most LLM inference providers + open-source frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "# simplest possible LLM call\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "oai = OpenAI()\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you please clarify what specific information or topic about Germany you’re interested in? For example, are you asking about Germany’s history, culture, economy, travel tips, politics, or something else? This will help me provide a more accurate and helpful response.\n"
     ]
    }
   ],
   "source": [
    "# why \"state\" matters\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What about Germany?\"},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What is the capital of France?\n",
      "assistant: The capital of France is Paris.\n",
      "user: What about Germany?\n",
      "assistant: The capital of Germany is Berlin.\n"
     ]
    }
   ],
   "source": [
    "# trying again\n",
    "\n",
    "history = [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=history, # type: ignore\n",
    ")\n",
    "history.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content}) # type: ignore\n",
    "history.append({\"role\": \"user\", \"content\": \"What about Germany?\"})\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=history, # type: ignore\n",
    ")\n",
    "history.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content}) # type: ignore\n",
    "for h in history:\n",
    "    print(f\"{h['role']}: {h['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Responses\n",
    "\n",
    "Pros: \n",
    "- Convenient features for conversation management, tool calls, \"thinking\" summaries\n",
    "- Primary method used in up-to-date OpenAI docs, plays nicely with some model features (e.g. multimodal, image output)\n",
    "\n",
    "Cons:\n",
    "- Not yet adopted by many frameworks/providers, mostly just OpenAI\n",
    "- potential for \"vendor lock-in\"\n",
    "- most features not too hard to DIY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "# message lists\n",
    "\n",
    "response = oai.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "print(response.output[0].content[0].text) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "The capital of Germany is Berlin.\n"
     ]
    }
   ],
   "source": [
    "# plain text\n",
    "\n",
    "response = oai.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=\"What is the capital of France?\",\n",
    ")\n",
    "id = response.id\n",
    "output_text = response.output_text\n",
    "print(output_text)\n",
    "\n",
    "# state management with ids \n",
    "\n",
    "response = oai.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=\"What about Germany?\",\n",
    "    previous_response_id=id,\n",
    ")\n",
    "id = response.id\n",
    "output_text = response.output_text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'detail': 'Not Found'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      6\u001b[39m response = deepinfra.chat.completions.create(\n\u001b[32m      7\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mmicrosoft/phi-4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     messages=[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWhat is the capital of France?\u001b[39m\u001b[33m\"\u001b[39m}],\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.choices[\u001b[32m0\u001b[39m].message.content)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m response = \u001b[43mdeepinfra\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicrosoft/phi-4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the capital of France?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.output_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/openai/resources/responses/responses.py:701\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, input, model, background, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, prompt, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    669\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    671\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    699\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    700\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'detail': 'Not Found'}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "deepinfra = OpenAI(base_url=os.getenv(\"DEEPINFRA_API_URL\"), api_key=os.getenv(\"DEEPINFRA_API_KEY\"))\n",
    "\n",
    "response = deepinfra.chat.completions.create(\n",
    "    model=\"microsoft/phi-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "response = deepinfra.responses.create(\n",
    "    model=\"microsoft/phi-4\",\n",
    "    input=\"What is the capital of France?\",\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Calling + Parsing Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you please specify whether you want the temperature in Celsius or Fahrenheit?\n"
     ]
    }
   ],
   "source": [
    "# DIY tool calling -- attempt 1\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You have access to a weather tool.\n",
    "\n",
    "Args:\n",
    "- city: str\n",
    "- country: str\n",
    "- scale: str (e.g. \"celsius\", \"fahrenheit\")\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"What's the weather like in Tokyo?\"\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me check the current weather in Tokyo for you.\n",
      "ChatCompletion(id='chatcmpl-BjY2wjKtmK8FZyObb7YBgeyLjVVTn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Let me check the current weather in Tokyo for you.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1750195334, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_6f2eabb9a5', usage=CompletionUsage(completion_tokens=11, prompt_tokens=57, total_tokens=68, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# DIY tool calling -- attempt 2\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You have access to a weather tool.\n",
    "\n",
    "Args:\n",
    "- city: str\n",
    "- country: str\n",
    "- scale: str (e.g. \"celsius\", \"fahrenheit\")\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"What's the weather like in Tokyo in Celsius?\"\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"tool\": \"weather\", \"args\": {\"city\": \"Tokyo\", \"country\": \"Japan\", \"scale\": \"celsius\"}}\n",
      "tool: weather\n",
      "args: {'city': 'Tokyo', 'country': 'Japan', 'scale': 'celsius'}\n",
      "  city: Tokyo\n",
      "  country: Japan\n",
      "  scale: celsius\n",
      "Calling tool weather with args {'city': 'Tokyo', 'country': 'Japan', 'scale': 'celsius'}\n",
      "The weather in Tokyo, Japan is 20 degrees (celsius).\n"
     ]
    }
   ],
   "source": [
    "# DIY tool calling -- attempt 3\n",
    "\n",
    "import json\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You have access to a weather tool.\n",
    "\n",
    "Args:\n",
    "- city: str\n",
    "- country: str\n",
    "- scale: str (e.g. \"celsius\", \"fahrenheit\")\n",
    "\n",
    "Call a tool by returning a JSON object with the following fields:\n",
    "- tool: str\n",
    "- args: dict\n",
    "\n",
    "Example:\n",
    "{\"tool\": \"weather\", \"args\": {\"city\": \"San Francisco\", \"country\": \"USA\", \"scale\": \"fahrenheit\"}}\n",
    "\"\"\"\n",
    "\n",
    "def dummy_weather_tool(city: str, country: str, scale: str):\n",
    "    return f\"The weather in {city}, {country} is 20 degrees ({scale}).\"\n",
    "\n",
    "tools = {\n",
    "    \"weather\": dummy_weather_tool,\n",
    "}\n",
    "\n",
    "def call_tool(tool: str, args: dict):\n",
    "    print(f\"Calling tool {tool} with args {args}\")\n",
    "    return tools[tool](**args)\n",
    "\n",
    "user_prompt = \"What's the weather like in Tokyo?\"\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    ")\n",
    "response_str = response.choices[0].message.content\n",
    "print(response_str)\n",
    "\n",
    "response_json = json.loads(response_str) # type: ignore\n",
    "for k, v in response_json.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "    if isinstance(v, dict):\n",
    "        for k2, v2 in v.items():\n",
    "            print(f\"  {k2}: {v2}\")\n",
    "\n",
    "tool_response = call_tool(response_json[\"tool\"], response_json[\"args\"])\n",
    "print(tool_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will check the current weather in Tokyo in Celsius for you.\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m response_str = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(response_str)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m response_json = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_str\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m response_json.items():\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    353\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# DIY tool calling with CoT -- attempt 4 \n",
    "\n",
    "import json\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You have access to a 'weather' tool. **Always think step-by-step before calling a tool.**\n",
    "\n",
    "Args:\n",
    "- city: str\n",
    "- country: str\n",
    "- scale: str (e.g. \"celsius\", \"fahrenheit\")\n",
    "\n",
    "Call a tool by returning a JSON object with the following fields:\n",
    "- tool: str\n",
    "- args: dict\n",
    "\n",
    "Example:\n",
    "I should call the weather tool with the given args:\n",
    "{\"tool\": \"weather\", \"args\": {\"city\": \"San Francisco\", \"country\": \"USA\", \"scale\": \"fahrenheit\"}}\n",
    "\"\"\"\n",
    "\n",
    "def dummy_weather_tool(city: str, country: str, scale: str):\n",
    "    return f\"The weather in {city}, {country} is 20 degrees ({scale}).\"\n",
    "\n",
    "tools = {\n",
    "    \"weather\": dummy_weather_tool,\n",
    "}\n",
    "\n",
    "def call_tool(tool: str, args: dict):\n",
    "    print(f\"Calling tool {tool} with args {args}\")\n",
    "    return tools[tool](**args)\n",
    "\n",
    "user_prompt = \"What's the weather like in Tokyo in Celsius?\"\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    ")\n",
    "response_str = response.choices[0].message.content\n",
    "print(response_str)\n",
    "\n",
    "response_json = json.loads(response_str) # type: ignore\n",
    "for k, v in response_json.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "    if isinstance(v, dict):\n",
    "        for k2, v2 in v.items():\n",
    "            print(f\"  {k2}: {v2}\")\n",
    "\n",
    "tool_response = call_tool(response_json[\"tool\"], response_json[\"args\"])\n",
    "print(tool_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'Tokyo', 'country': 'Japan', 'scale': 'celsius'}\n"
     ]
    }
   ],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the weather for a given city\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city to get the weather for\"\n",
    "                },\n",
    "                \"country\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The country to get the weather for\"\n",
    "                },\n",
    "                \"scale\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The scale to get the weather for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"city\", \"country\", \"scale\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}],\n",
    "    tools=tools, # type: ignore\n",
    ")\n",
    "\n",
    "tool_args = json.loads(response.choices[0].message.tool_calls[0].function.arguments) # type: ignore\n",
    "print(tool_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_bDxoE3P0XWQ6AYIlXw6Lm72B', function=Function(arguments='{\"city\":\"Tokyo\",\"country\":\"Japan\",\"scale\":\"celsius\"}', name='get_weather'), type='function')]))\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "think='I need to know the temperature scale to provide the weather information for Tokyo. Assuming Celsius as the default scale.' args=WeatherArgs(city='Tokyo', country='Japan', scale='celsius')\n"
     ]
    }
   ],
   "source": [
    "# pydantic structured outputs\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class WeatherArgs(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "    scale: Literal[\"celsius\", \"fahrenheit\"]\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    think: str\n",
    "    args: WeatherArgs\n",
    "\n",
    "\n",
    "response = oai.beta.chat.completions.parse(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}],\n",
    "    response_format=WeatherResponse,\n",
    ")\n",
    "response_obj = response.choices[0].message.parsed\n",
    "print(response_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'celsius'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_obj.args.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"tool\": \"weather\", \"args\": {\"city\": \"Tokyo\", \"country\": \"Japan\", \"scale\": \"celsius\"}}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You have access to a 'weather' tool.\n",
    "\n",
    "Args:\n",
    "- city: str\n",
    "- country: str\n",
    "- scale: str (e.g. \"celsius\", \"fahrenheit\")\n",
    "\n",
    "Call a tool by returning a JSON object with the following fields:\n",
    "- tool: str\n",
    "- args: dict\n",
    "\n",
    "Example:\n",
    "{\"tool\": \"weather\", \"args\": {\"city\": \"San Francisco\", \"country\": \"USA\", \"scale\": \"fahrenheit\"}}\n",
    "\"\"\"\n",
    "\n",
    "response = oai.beta.chat.completions.parse(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}],\n",
    "    response_format={\"type\": \"json_object\"}, # type: ignore\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"tool\": \"weather\", \"args\": {\"city\": \"Tokyo\", \"country\": \"Japan\", \"scale\": \"celsius\"}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# not all providers suppport pydantic structured outputs natively\n",
    "\n",
    "class WeatherArgs(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "    scale: str\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    think: str\n",
    "    args: WeatherArgs\n",
    "\n",
    "deepinfra = OpenAI(base_url=os.getenv(\"DEEPINFRA_API_URL\"), api_key=os.getenv(\"DEEPINFRA_API_KEY\"))\n",
    "\n",
    "response = deepinfra.beta.chat.completions.parse(\n",
    "    model=\"microsoft/phi-4\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}],\n",
    "    response_format={\"type\": \"json_object\"}, # type: ignore\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "think='To provide the weather information for Tokyo, I need to call the weather tool with the appropriate arguments.' args=WeatherArgs(city='Tokyo', country='Japan', scale='celsius')\n"
     ]
    }
   ],
   "source": [
    "import instructor\n",
    "from instructor import Mode \n",
    "deepinfra_i = instructor.from_openai(deepinfra, mode=Mode.JSON)\n",
    "\n",
    "response = deepinfra_i.chat.completions.create(\n",
    "    model=\"microsoft/phi-4\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}], # type: ignore\n",
    "    response_model=WeatherResponse,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have access to a 'weather' tool. **Always think step-by-step before calling a tool.**\n",
      "\n",
      "Args:\n",
      "- city: str\n",
      "- country: str\n",
      "- scale: str (e.g. \"celsius\", \"fahrenheit\")\n",
      "\n",
      "Respond in the following XML format:\n",
      "<reasoning>\n",
      "...\n",
      "</reasoning>\n",
      "<[ tool | answer ]>\n",
      "...\n",
      "</[ tool | answer ]>\n",
      "\n",
      "For tool calls, return a JSON object inside the 'tool' section with the following fields:\n",
      "- tool: str (e.g. \"weather\")\n",
      "- args: dict (e.g. {\"city\": \"San Francisco\", \"country\": \"USA\", \"scale\": \"fahrenheit\"})\n",
      "\n",
      "---\n",
      "<reasoning>\n",
      "To provide the weather details for Tokyo, I need the temperature in a specific scale. The most commonly used scales for temperature are Celsius and Fahrenheit. To proceed, I will assume Celsius as it is widely used worldwide, especially in Tokyo. However, I would need to confirm this assumption or convert it to another scale if specified. Therefore, I will use the 'weather' tool to get the current weather in Tokyo measured in Celsius.\n",
      "</reasoning>\n",
      "<tool>\n",
      "{\n",
      "  \"tool\": \"weather\",\n",
      "  \"args\": {\n",
      "    \"city\": \"Tokyo\",\n",
      "    \"country\": \"JP\",\n",
      "    \"scale\": \"celsius\"\n",
      "  }\n",
      "}\n",
      "</tool>\n",
      "---\n",
      "To provide the weather details for Tokyo, I need the temperature in a specific scale. The most commonly used scales for temperature are Celsius and Fahrenheit. To proceed, I will assume Celsius as it is widely used worldwide, especially in Tokyo. However, I would need to confirm this assumption or convert it to another scale if specified. Therefore, I will use the 'weather' tool to get the current weather in Tokyo measured in Celsius.\n",
      "{\n",
      "  \"tool\": \"weather\",\n",
      "  \"args\": {\n",
      "    \"city\": \"Tokyo\",\n",
      "    \"country\": \"JP\",\n",
      "    \"scale\": \"celsius\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "### XML\n",
    "\n",
    "# uv add https://github.com/willccbb/verifiers.git\n",
    "\n",
    "import verifiers as vf \n",
    "\n",
    "parser = vf.XMLParser(fields=[\"reasoning\", (\"tool\", \"answer\")], answer_field=\"answer\")\n",
    "\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You have access to a 'weather' tool. **Always think step-by-step before calling a tool.**\n",
    "\n",
    "Args:\n",
    "- city: str\n",
    "- country: str\n",
    "- scale: str (e.g. \"celsius\", \"fahrenheit\")\n",
    "\n",
    "Respond in the following XML format:\n",
    "{parser.get_format_str()}\n",
    "\n",
    "For tool calls, return a JSON object inside the 'tool' section with the following fields:\n",
    "- tool: str (e.g. \"weather\")\n",
    "- args: dict (e.g. {{\"city\": \"San Francisco\", \"country\": \"USA\", \"scale\": \"fahrenheit\"}})\n",
    "\"\"\"\n",
    "\n",
    "print(system_prompt)\n",
    "print('---')\n",
    "\n",
    "response = deepinfra.chat.completions.create(\n",
    "    model=\"microsoft/phi-4\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}], # type: ignore\n",
    ")\n",
    "response_str = response.choices[0].message.content\n",
    "print(response_str)\n",
    "print('---')\n",
    "parsed = parser.parse(response_str) \n",
    "print(parsed.reasoning)\n",
    "print(parsed.tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tool': 'weather', 'args': {'city': 'Tokyo', 'country': 'Japan', 'scale': 'celsius'}}\n"
     ]
    }
   ],
   "source": [
    "tool_args = json.loads(parsed.tool)\n",
    "print(tool_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for self-hosting:\n",
    "- vLLM + SGLang\n",
    "- both support Outlines + XGrammar as structured output parsers\n",
    "- regex, json, \n",
    "\n",
    "Links:\n",
    "- https://dottxt-ai.github.io/outlines/reference/generation/regex/\n",
    "- https://dottxt-ai.github.io/outlines/reference/generation/types/\n",
    "- https://xgrammar.mlc.ai/docs/how_to/json_generation.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many Flavors of ReAct\n",
    "\n",
    "\n",
    "Seminal paper: https://react-lm.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Doc Search Agent\n",
    "\n",
    "Setup:\n",
    "- input question\n",
    "- multiple tools\n",
    "- some end state (e.g giving an answer, response with no tool calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2590\n",
      "['William McKinley.md', \"A Midsummer Night's Dream.md\", 'Robert Duvall.md', 'Chi-squared test.md', 'The Office _British TV series.md', 'Poseidon.md', 'Shinto.md', 'SZA.md', 'XNXX.md', 'Alanis Morissette.md']\n"
     ]
    }
   ],
   "source": [
    "# count number of files in data/wiki\n",
    "import os\n",
    "print(len(os.listdir(\"data/wiki\")))\n",
    "first_ten_files = os.listdir(\"data/wiki\")[:10]\n",
    "print(first_ten_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize/load the collection\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Setup\n",
    "WIKI_DIR = \"data/wiki\"  # Path relative to notebook location\n",
    "CHROMA_DB_DIR = \".chroma_db\"  # Directory for persistent ChromaDB storage\n",
    "\n",
    "# Create persistent ChromaDB client\n",
    "db_client = chromadb.PersistentClient(path=CHROMA_DB_DIR)\n",
    "\n",
    "# Create embedding function using OpenAI\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "def init_collection():\n",
    "    \"\"\"Initialize ChromaDB collection with wiki page titles\"\"\"\n",
    "    try:\n",
    "        # Try to get existing collection\n",
    "        collection = db_client.get_collection(\"wiki_titles\", embedding_function=openai_ef)\n",
    "        return collection\n",
    "    except:\n",
    "        # Create new collection and index all titles\n",
    "        collection = db_client.create_collection(\"wiki_titles\", embedding_function=openai_ef)\n",
    "        \n",
    "        # Get all wiki files\n",
    "        wiki_files = [f for f in os.listdir(WIKI_DIR) if f.endswith('.md')]\n",
    "        \n",
    "        # Add documents to collection\n",
    "        documents = []\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        \n",
    "        for filename in wiki_files:\n",
    "            # Create page ID from filename (remove .md extension)\n",
    "            title = filename[:-3]\n",
    "            # remove special characters\n",
    "            page_id = title.replace(' ', '_').lower()\n",
    "            \n",
    "            documents.append(title)\n",
    "            ids.append(page_id)\n",
    "            metadatas.append({\"page_id\": page_id, \"title\": title})\n",
    "\n",
    "        # Add in batches of 100\n",
    "        batch_size = 100\n",
    "        for i in range(0, len(documents), batch_size):\n",
    "            collection.add(\n",
    "                documents=documents[i:i+batch_size],\n",
    "                ids=ids[i:i+batch_size],\n",
    "                metadatas=metadatas[i:i+batch_size]\n",
    "            )\n",
    "        \n",
    "        return collection\n",
    "\n",
    "# Initialize collection on notebook load\n",
    "collection = init_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2590\n",
      "[Collection(name=wiki_titles)]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "db_client = chromadb.PersistentClient(path=\".chroma_db\")\n",
    "\n",
    "# count number of entries in wiki_titles collection\n",
    "print(db_client.get_collection(\"wiki_titles\").count())\n",
    "\n",
    "# get all collections\n",
    "print(db_client.list_collections())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'page_id': 'basketball_positions', 'title': 'Basketball positions'}, {'page_id': 'baseball', 'title': 'Baseball'}, {'page_id': 'basketball_wives', 'title': 'Basketball Wives'}, {'page_id': 'reggie_jackson__basketball,_born_1990', 'title': 'Reggie Jackson _basketball, born 1990'}, {'page_id': \"united_states_men's_national_basketball_team\", 'title': \"United States men's national basketball team\"}, {'page_id': 'chicago_bulls', 'title': 'Chicago Bulls'}, {'page_id': 'blake_griffin', 'title': 'Blake Griffin'}, {'page_id': 'jeremy_lin', 'title': 'Jeremy Lin'}, {'page_id': 'lamelo_ball', 'title': 'LaMelo Ball'}, {'page_id': '1984_nba_draft', 'title': '1984 NBA draft'}]\n"
     ]
    }
   ],
   "source": [
    "def search_pages(query: str) -> list[dict]:\n",
    "    \"\"\"Search for top 10 relevant articles using title embedding similarity.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search for.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dicts with page_id and title.\n",
    "\n",
    "    Examples:\n",
    "        \"basketball\" -> [{\"page_id\": \"basketball\", \"title\": \"Basketball\"}, {\"page_id\": \"basketball_rules\", \"title\": \"Basketball Rules\"}, ...]\n",
    "    \"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=10\n",
    "    )\n",
    "    \n",
    "    # Format results\n",
    "    output = []\n",
    "    for i in range(len(results['ids'][0])):\n",
    "        output.append({\n",
    "            \"page_id\": results['ids'][0][i],\n",
    "            \"title\": results['metadatas'][0][i]['title'] # type: ignore\n",
    "        })\n",
    "    \n",
    "    return output\n",
    "\n",
    "# test search_pages\n",
    "print(search_pages(\"basketball\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'section_id': 'baseball:baseball', 'section_name': 'Baseball'},\n",
       " {'section_id': 'baseball:rules_and_gameplay',\n",
       "  'section_name': 'Rules and gameplay'},\n",
       " {'section_id': 'baseball:personnel', 'section_name': 'Personnel'},\n",
       " {'section_id': 'baseball:players', 'section_name': 'Players'},\n",
       " {'section_id': 'baseball:managers_and_coaches',\n",
       "  'section_name': 'Managers and coaches'},\n",
       " {'section_id': 'baseball:umpires', 'section_name': 'Umpires'},\n",
       " {'section_id': 'baseball:strategy', 'section_name': 'Strategy'},\n",
       " {'section_id': 'baseball:tactics', 'section_name': 'Tactics'},\n",
       " {'section_id': 'baseball:pitching_and_fielding',\n",
       "  'section_name': 'Pitching and fielding'},\n",
       " {'section_id': 'baseball:batting_and_baserunning',\n",
       "  'section_name': 'Batting and baserunning'},\n",
       " {'section_id': 'baseball:history', 'section_name': 'History'},\n",
       " {'section_id': 'baseball:in_the_united_states',\n",
       "  'section_name': 'In the United States'},\n",
       " {'section_id': 'baseball:establishment_of_professional_leagues',\n",
       "  'section_name': 'Establishment of professional leagues'},\n",
       " {'section_id': 'baseball:rise_of_ruth_and_racial_integration',\n",
       "  'section_name': 'Rise of Ruth and racial integration'},\n",
       " {'section_id': 'baseball:attendance_records_and_the_age_of_steroids',\n",
       "  'section_name': 'Attendance records and the age of steroids'},\n",
       " {'section_id': 'baseball:around_the_world',\n",
       "  'section_name': 'Around the world'},\n",
       " {'section_id': 'baseball:distinctive_elements',\n",
       "  'section_name': 'Distinctive elements'},\n",
       " {'section_id': 'baseball:no_clock_to_kill',\n",
       "  'section_name': 'No clock to kill'},\n",
       " {'section_id': 'baseball:individual_focus',\n",
       "  'section_name': 'Individual focus'},\n",
       " {'section_id': 'baseball:uniqueness_of_parks',\n",
       "  'section_name': 'Uniqueness of parks'},\n",
       " {'section_id': 'baseball:statistics', 'section_name': 'Statistics'},\n",
       " {'section_id': 'baseball:sabermetrics', 'section_name': 'Sabermetrics'},\n",
       " {'section_id': 'baseball:popularity_and_cultural_impact',\n",
       "  'section_name': 'Popularity and cultural impact'},\n",
       " {'section_id': 'baseball:in_the_united_states',\n",
       "  'section_name': 'In the United States'},\n",
       " {'section_id': 'baseball:caribbean', 'section_name': 'Caribbean'},\n",
       " {'section_id': 'baseball:asia', 'section_name': 'Asia'},\n",
       " {'section_id': 'baseball:among_children', 'section_name': 'Among children'},\n",
       " {'section_id': 'baseball:in_popular_culture',\n",
       "  'section_name': 'In popular culture'},\n",
       " {'section_id': 'baseball:derivative_games',\n",
       "  'section_name': 'Derivative games'},\n",
       " {'section_id': 'baseball:british_baseball',\n",
       "  'section_name': 'British baseball'},\n",
       " {'section_id': 'baseball:finnish_baseball',\n",
       "  'section_name': 'Finnish baseball'},\n",
       " {'section_id': 'baseball:see_also', 'section_name': 'See also'},\n",
       " {'section_id': 'baseball:related_sports', 'section_name': 'Related sports'},\n",
       " {'section_id': 'baseball:citations', 'section_name': 'Citations'},\n",
       " {'section_id': 'baseball:general_and_cited_sources',\n",
       "  'section_name': 'General and cited sources'},\n",
       " {'section_id': 'baseball:further_reading', 'section_name': 'Further reading'},\n",
       " {'section_id': 'baseball:external_links', 'section_name': 'External links'}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def view_sections(page_id: str) -> list[dict]:\n",
    "    \"\"\"View the sections of a page.\n",
    "    \n",
    "    Args:\n",
    "        page_id (str): The ID of the page to view.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dicts with section_id and section_name.\n",
    "\n",
    "    Examples:\n",
    "        \"basketball\" -> [{\"section_id\": \"basketball:history\", \"section_name\": \"History\"}, ...]\n",
    "    \"\"\"\n",
    "    # Find the file for this page_id\n",
    "    results = collection.get(ids=[page_id])\n",
    "    if not results['ids']:\n",
    "        raise ValueError(f\"Page not found: {page_id}\")\n",
    "    \n",
    "    filename = results['metadatas'][0]['title'] + '.md'  # type: ignore\n",
    "    filepath = os.path.join(WIKI_DIR, filename) # type: ignore\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    sections = []\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith('#'):\n",
    "            # Extract section name (remove # and whitespace)\n",
    "            section_name = line.lstrip('#').strip()\n",
    "            # Create section ID\n",
    "            section_id = f\"{page_id}:{section_name.lower().replace(' ', '_')}\"\n",
    "            sections.append({\n",
    "                \"section_id\": section_id,\n",
    "                \"section_name\": section_name,\n",
    "                \"start_line\": i\n",
    "            })\n",
    "    \n",
    "    # If no sections found, return the whole page as one section\n",
    "    if not sections:\n",
    "        sections.append({\n",
    "            \"section_id\": f\"{page_id}:full\",\n",
    "            \"section_name\": \"Full Page\",\n",
    "            \"start_line\": 0\n",
    "        })\n",
    "    \n",
    "    return [{\"section_id\": s[\"section_id\"], \"section_name\": s[\"section_name\"]} \n",
    "            for s in sections]\n",
    "\n",
    "\n",
    "# test view_sections\n",
    "view_sections(\"baseball\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Finnish baseball\n",
      "\n",
      "Finnish baseball, known as pesäpallo, is a combination of traditional ball-batting team games and North American baseball, invented by [\"Tahko\" Pihkala](Lauri)(Lauri Pihkala) in the 1920s. The basic idea of pesäpallo is similar to that of baseball: the offense tries to score by hitting the ball successfully and running through the bases, while the defense tries to put the batter and runners out. One of the most important differences between pesäpallo and baseball is that the ball is pitched vertically, which makes hitting the ball, as well as controlling the power and direction of the hit, much easier. This gives the offensive game more variety, speed, and tactical aspects compared to baseball.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_section(section_id: str) -> str:\n",
    "    \"\"\"Read a section of a page.\n",
    "    \n",
    "    Args:\n",
    "        section_id (str): The ID of the section to read.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the section.\n",
    "        \n",
    "    Examples:\n",
    "        \"baseball:finnish_baseball\" -> \"Finnish baseball is a sport that is played in Finland...\"\n",
    "    \"\"\"\n",
    "    # Parse section_id\n",
    "    if ':' not in section_id:\n",
    "        raise ValueError(\"Invalid section_id format. Expected: page_id:section_name\")\n",
    "    \n",
    "    page_id, section_name_id = section_id.split(':', 1)\n",
    "    \n",
    "    # Get the file\n",
    "    results = collection.get(ids=[page_id])\n",
    "    if not results['ids']:\n",
    "        raise ValueError(f\"Page not found: {page_id}\")\n",
    "    \n",
    "    filename = results['metadatas'][0]['title'] + '.md' # type: ignore\n",
    "    filepath = os.path.join(WIKI_DIR, filename)\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    \n",
    "    # Special case for \"full\" section\n",
    "    if section_name_id == \"full\":\n",
    "        return content\n",
    "    \n",
    "    # Find the section\n",
    "    section_start = None\n",
    "    section_end = None\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith('#'):\n",
    "            current_section = line.lstrip('#').strip().lower().replace(' ', '_')\n",
    "            if current_section == section_name_id and section_start is None:\n",
    "                section_start = i\n",
    "            elif section_start is not None and section_end is None:\n",
    "                section_end = i\n",
    "                break\n",
    "    \n",
    "    # If section found\n",
    "    if section_start is not None:\n",
    "        if section_end is None:\n",
    "            section_end = len(lines)\n",
    "        return '\\n'.join(lines[section_start:section_end])\n",
    "    else:\n",
    "        raise ValueError(f\"Section not found: {section_id}\")\n",
    "    \n",
    "print(read_section(\"baseball:finnish_baseball\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft's acquisition of ZeniMax Media in 2020 was valued at approximately $7.5 billion.\n"
     ]
    }
   ],
   "source": [
    "# sample question where default answer is wrong (according to docs)\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What was the value of Microsoft's acquisition deal for ZeniMax Media in 2020?\"}],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining tools via OpenAI Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft's acquisition deal for ZeniMax Media in 2020 was valued at $7.5 billion.\n"
     ]
    }
   ],
   "source": [
    "# openai agents sdk\n",
    "# uv add openai-agents\n",
    "\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    name=\"wiki_agent\",\n",
    "    tools=[],\n",
    ")\n",
    "\n",
    "# no tools\n",
    "result = Runner.run_sync(agent, \"What was the value of Microsoft's acquisition deal for ZeniMax Media in 2020?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of Microsoft's acquisition deal for ZeniMax Media in 2020 was $8.1 billion in cash. The acquisition was intended to expand the library of Xbox Game Pass and XCloud and was completed by March 9, 2021.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, function_tool # type: ignore\n",
    "\n",
    "\n",
    "# async wrappers\n",
    "@function_tool\n",
    "async def search_pages_fn(query: str) -> list[dict]:\n",
    "    \"\"\"Search for top 10 relevant articles using title embedding similarity.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search for.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dicts with page_id and title.\n",
    "\n",
    "    Examples:\n",
    "        \"basketball\" -> [{\"page_id\": \"basketball\", \"title\": \"Basketball\"}, {\"page_id\": \"basketball_rules\", \"title\": \"Basketball Rules\"}, ...]\n",
    "    \"\"\"\n",
    "    return search_pages(query)\n",
    "\n",
    "@function_tool\n",
    "async def view_sections_fn(page_id: str) -> list[dict]:\n",
    "    \"\"\"View the sections of a page.\n",
    "    \n",
    "    Args:\n",
    "        page_id (str): The ID of the page to view.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dicts with section_id and section_name.\n",
    "\n",
    "    Examples:\n",
    "        \"basketball\" -> [{\"section_id\": \"basketball:history\", \"section_name\": \"History\"}, ...]\n",
    "    \"\"\"\n",
    "    return view_sections(page_id)\n",
    "\n",
    "@function_tool\n",
    "async def read_section_fn(section_id: str) -> str:\n",
    "    \"\"\"Read a section of a wiki page.\n",
    "    \n",
    "    Args:\n",
    "        section_id (str): The ID of the section to read.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the section.    \n",
    "\n",
    "    Examples:\n",
    "        \"basketball:history\" -> \"The history of basketball...\"\n",
    "    \"\"\"\n",
    "    return read_section(section_id)\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    name=\"wiki_agent\",\n",
    "    tools=[search_pages_fn, view_sections_fn, read_section_fn],\n",
    ")\n",
    "\n",
    "result = Runner.run_sync(agent, \"What was the value of Microsoft's acquisition deal for ZeniMax Media in 2020?\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolCallItem(agent=Agent(name='wiki_agent', instructions=None, prompt=None, handoff_description=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='search_pages_fn', description='Search for top 10 relevant articles using title embedding similarity.', params_json_schema={'properties': {'query': {'description': 'The query to search for.', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_pages_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x11dd93d80>, strict_json_schema=True, is_enabled=True), FunctionTool(name='view_sections_fn', description='View the sections of a page.', params_json_schema={'properties': {'page_id': {'description': 'The ID of the page to view.', 'title': 'Page Id', 'type': 'string'}}, 'required': ['page_id'], 'title': 'view_sections_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x177f22f20>, strict_json_schema=True, is_enabled=True), FunctionTool(name='read_section_fn', description='Read a section of a wiki page.', params_json_schema={'properties': {'section_id': {'description': 'The ID of the section to read.', 'title': 'Section Id', 'type': 'string'}}, 'required': ['section_id'], 'title': 'read_section_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1078a6480>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"query\":\"Microsoft acquisition ZeniMax Media 2020\"}', call_id='call_UpnuK1tYMZYdD37w3rH4cvSJ', name='search_pages_fn', type='function_call', id='fc_6851b7483de0819c92c6c4139f36e6400dbb5dfc2ad9ac0d', status='completed'), type='tool_call_item')\n",
      "ToolCallOutputItem(agent=Agent(name='wiki_agent', instructions=None, prompt=None, handoff_description=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='search_pages_fn', description='Search for top 10 relevant articles using title embedding similarity.', params_json_schema={'properties': {'query': {'description': 'The query to search for.', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_pages_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x11dd93d80>, strict_json_schema=True, is_enabled=True), FunctionTool(name='view_sections_fn', description='View the sections of a page.', params_json_schema={'properties': {'page_id': {'description': 'The ID of the page to view.', 'title': 'Page Id', 'type': 'string'}}, 'required': ['page_id'], 'title': 'view_sections_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x177f22f20>, strict_json_schema=True, is_enabled=True), FunctionTool(name='read_section_fn', description='Read a section of a wiki page.', params_json_schema={'properties': {'section_id': {'description': 'The ID of the section to read.', 'title': 'Section Id', 'type': 'string'}}, 'required': ['section_id'], 'title': 'read_section_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1078a6480>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_UpnuK1tYMZYdD37w3rH4cvSJ', 'output': '[{\\'page_id\\': \\'xbox_game_studios\\', \\'title\\': \\'Xbox Game Studios\\'}, {\\'page_id\\': \\'xbox\\', \\'title\\': \\'Xbox\\'}, {\\'page_id\\': \\'xbox_series_x_and_series_s\\', \\'title\\': \\'Xbox Series X and Series S\\'}, {\\'page_id\\': \\'insomniac_games\\', \\'title\\': \\'Insomniac Games\\'}, {\\'page_id\\': \\'rockstar_games\\', \\'title\\': \\'Rockstar Games\\'}, {\\'page_id\\': \\'frictional_games\\', \\'title\\': \\'Frictional Games\\'}, {\\'page_id\\': \\'fallout_76\\', \\'title\\': \\'Fallout 76\\'}, {\\'page_id\\': \\'gabe_newell\\', \\'title\\': \\'Gabe Newell\\'}, {\\'page_id\\': \\'microsoft_teams\\', \\'title\\': \\'Microsoft Teams\\'}, {\\'page_id\\': \"assassin\\'s_creed_valhalla\", \\'title\\': \"Assassin\\'s Creed Valhalla\"}]', 'type': 'function_call_output'}, output=[{'page_id': 'xbox_game_studios', 'title': 'Xbox Game Studios'}, {'page_id': 'xbox', 'title': 'Xbox'}, {'page_id': 'xbox_series_x_and_series_s', 'title': 'Xbox Series X and Series S'}, {'page_id': 'insomniac_games', 'title': 'Insomniac Games'}, {'page_id': 'rockstar_games', 'title': 'Rockstar Games'}, {'page_id': 'frictional_games', 'title': 'Frictional Games'}, {'page_id': 'fallout_76', 'title': 'Fallout 76'}, {'page_id': 'gabe_newell', 'title': 'Gabe Newell'}, {'page_id': 'microsoft_teams', 'title': 'Microsoft Teams'}, {'page_id': \"assassin's_creed_valhalla\", 'title': \"Assassin's Creed Valhalla\"}], type='tool_call_output_item')\n",
      "ToolCallItem(agent=Agent(name='wiki_agent', instructions=None, prompt=None, handoff_description=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='search_pages_fn', description='Search for top 10 relevant articles using title embedding similarity.', params_json_schema={'properties': {'query': {'description': 'The query to search for.', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_pages_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x11dd93d80>, strict_json_schema=True, is_enabled=True), FunctionTool(name='view_sections_fn', description='View the sections of a page.', params_json_schema={'properties': {'page_id': {'description': 'The ID of the page to view.', 'title': 'Page Id', 'type': 'string'}}, 'required': ['page_id'], 'title': 'view_sections_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x177f22f20>, strict_json_schema=True, is_enabled=True), FunctionTool(name='read_section_fn', description='Read a section of a wiki page.', params_json_schema={'properties': {'section_id': {'description': 'The ID of the section to read.', 'title': 'Section Id', 'type': 'string'}}, 'required': ['section_id'], 'title': 'read_section_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1078a6480>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"page_id\":\"xbox_game_studios\"}', call_id='call_Lhxm9RbQOg1eT3pa35xftnSl', name='view_sections_fn', type='function_call', id='fc_6851b7498488819cb0114aaaea3add4b0dbb5dfc2ad9ac0d', status='completed'), type='tool_call_item')\n",
      "ToolCallOutputItem(agent=Agent(name='wiki_agent', instructions=None, prompt=None, handoff_description=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='search_pages_fn', description='Search for top 10 relevant articles using title embedding similarity.', params_json_schema={'properties': {'query': {'description': 'The query to search for.', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_pages_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x11dd93d80>, strict_json_schema=True, is_enabled=True), FunctionTool(name='view_sections_fn', description='View the sections of a page.', params_json_schema={'properties': {'page_id': {'description': 'The ID of the page to view.', 'title': 'Page Id', 'type': 'string'}}, 'required': ['page_id'], 'title': 'view_sections_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x177f22f20>, strict_json_schema=True, is_enabled=True), FunctionTool(name='read_section_fn', description='Read a section of a wiki page.', params_json_schema={'properties': {'section_id': {'description': 'The ID of the section to read.', 'title': 'Section Id', 'type': 'string'}}, 'required': ['section_id'], 'title': 'read_section_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1078a6480>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_Lhxm9RbQOg1eT3pa35xftnSl', 'output': \"[{'section_id': 'xbox_game_studios:xbox_game_studios', 'section_name': 'Xbox Game Studios'}, {'section_id': 'xbox_game_studios:history', 'section_name': 'History'}, {'section_id': 'xbox_game_studios:as_microsoft_games_and_microsoft_game_studios_(2000–2011)', 'section_name': 'As Microsoft Games and Microsoft Game Studios (2000–2011)'}, {'section_id': 'xbox_game_studios:as_microsoft_studios_(2011–2019)', 'section_name': 'As Microsoft Studios (2011–2019)'}, {'section_id': 'xbox_game_studios:shifting_priorities_under_microsoft_ceo_satya_nadella', 'section_name': 'Shifting priorities under Microsoft CEO Satya Nadella'}, {'section_id': 'xbox_game_studios:as_xbox_game_studios_(2019–present)', 'section_name': 'As Xbox Game Studios (2019–present)'}, {'section_id': 'xbox_game_studios:subsidiaries_and_divisions', 'section_name': 'Subsidiaries and divisions'}, {'section_id': 'xbox_game_studios:former', 'section_name': 'Former'}, {'section_id': 'xbox_game_studios:games_published', 'section_name': 'Games published'}, {'section_id': 'xbox_game_studios:references', 'section_name': 'References'}, {'section_id': 'xbox_game_studios:external_links', 'section_name': 'External links'}]\", 'type': 'function_call_output'}, output=[{'section_id': 'xbox_game_studios:xbox_game_studios', 'section_name': 'Xbox Game Studios'}, {'section_id': 'xbox_game_studios:history', 'section_name': 'History'}, {'section_id': 'xbox_game_studios:as_microsoft_games_and_microsoft_game_studios_(2000–2011)', 'section_name': 'As Microsoft Games and Microsoft Game Studios (2000–2011)'}, {'section_id': 'xbox_game_studios:as_microsoft_studios_(2011–2019)', 'section_name': 'As Microsoft Studios (2011–2019)'}, {'section_id': 'xbox_game_studios:shifting_priorities_under_microsoft_ceo_satya_nadella', 'section_name': 'Shifting priorities under Microsoft CEO Satya Nadella'}, {'section_id': 'xbox_game_studios:as_xbox_game_studios_(2019–present)', 'section_name': 'As Xbox Game Studios (2019–present)'}, {'section_id': 'xbox_game_studios:subsidiaries_and_divisions', 'section_name': 'Subsidiaries and divisions'}, {'section_id': 'xbox_game_studios:former', 'section_name': 'Former'}, {'section_id': 'xbox_game_studios:games_published', 'section_name': 'Games published'}, {'section_id': 'xbox_game_studios:references', 'section_name': 'References'}, {'section_id': 'xbox_game_studios:external_links', 'section_name': 'External links'}], type='tool_call_output_item')\n",
      "ToolCallItem(agent=Agent(name='wiki_agent', instructions=None, prompt=None, handoff_description=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='search_pages_fn', description='Search for top 10 relevant articles using title embedding similarity.', params_json_schema={'properties': {'query': {'description': 'The query to search for.', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_pages_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x11dd93d80>, strict_json_schema=True, is_enabled=True), FunctionTool(name='view_sections_fn', description='View the sections of a page.', params_json_schema={'properties': {'page_id': {'description': 'The ID of the page to view.', 'title': 'Page Id', 'type': 'string'}}, 'required': ['page_id'], 'title': 'view_sections_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x177f22f20>, strict_json_schema=True, is_enabled=True), FunctionTool(name='read_section_fn', description='Read a section of a wiki page.', params_json_schema={'properties': {'section_id': {'description': 'The ID of the section to read.', 'title': 'Section Id', 'type': 'string'}}, 'required': ['section_id'], 'title': 'read_section_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1078a6480>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"section_id\":\"xbox_game_studios:history\"}', call_id='call_kWnUjrDyhPATiNTV2vngViGu', name='read_section_fn', type='function_call', id='fc_6851b74afb10819cbb4e0f22580f09530dbb5dfc2ad9ac0d', status='completed'), type='tool_call_item')\n",
      "ToolCallOutputItem(agent=Agent(name='wiki_agent', instructions=None, prompt=None, handoff_description=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='search_pages_fn', description='Search for top 10 relevant articles using title embedding similarity.', params_json_schema={'properties': {'query': {'description': 'The query to search for.', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_pages_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x11dd93d80>, strict_json_schema=True, is_enabled=True), FunctionTool(name='view_sections_fn', description='View the sections of a page.', params_json_schema={'properties': {'page_id': {'description': 'The ID of the page to view.', 'title': 'Page Id', 'type': 'string'}}, 'required': ['page_id'], 'title': 'view_sections_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x177f22f20>, strict_json_schema=True, is_enabled=True), FunctionTool(name='read_section_fn', description='Read a section of a wiki page.', params_json_schema={'properties': {'section_id': {'description': 'The ID of the section to read.', 'title': 'Section Id', 'type': 'string'}}, 'required': ['section_id'], 'title': 'read_section_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1078a6480>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_kWnUjrDyhPATiNTV2vngViGu', 'output': '## History\\n', 'type': 'function_call_output'}, output='## History\\n', type='tool_call_output_item')\n",
      "ToolCallItem(agent=Agent(name='wiki_agent', instructions=None, prompt=None, handoff_description=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='search_pages_fn', description='Search for top 10 relevant articles using title embedding similarity.', params_json_schema={'properties': {'query': {'description': 'The query to search for.', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_pages_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x11dd93d80>, strict_json_schema=True, is_enabled=True), FunctionTool(name='view_sections_fn', description='View the sections of a page.', params_json_schema={'properties': {'page_id': {'description': 'The ID of the page to view.', 'title': 'Page Id', 'type': 'string'}}, 'required': ['page_id'], 'title': 'view_sections_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x177f22f20>, strict_json_schema=True, is_enabled=True), FunctionTool(name='read_section_fn', description='Read a section of a wiki page.', params_json_schema={'properties': {'section_id': {'description': 'The ID of the section to read.', 'title': 'Section Id', 'type': 'string'}}, 'required': ['section_id'], 'title': 'read_section_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1078a6480>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"section_id\":\"xbox_game_studios:as_xbox_game_studios_(2019–present)\"}', call_id='call_1pglzAhrH4uqpoZhuHNeY1pF', name='read_section_fn', type='function_call', id='fc_6851b74bd774819cbb1757c5569cc6350dbb5dfc2ad9ac0d', status='completed'), type='tool_call_item')\n",
      "ToolCallOutputItem(agent=Agent(name='wiki_agent', instructions=None, prompt=None, handoff_description=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='search_pages_fn', description='Search for top 10 relevant articles using title embedding similarity.', params_json_schema={'properties': {'query': {'description': 'The query to search for.', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_pages_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x11dd93d80>, strict_json_schema=True, is_enabled=True), FunctionTool(name='view_sections_fn', description='View the sections of a page.', params_json_schema={'properties': {'page_id': {'description': 'The ID of the page to view.', 'title': 'Page Id', 'type': 'string'}}, 'required': ['page_id'], 'title': 'view_sections_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x177f22f20>, strict_json_schema=True, is_enabled=True), FunctionTool(name='read_section_fn', description='Read a section of a wiki page.', params_json_schema={'properties': {'section_id': {'description': 'The ID of the section to read.', 'title': 'Section Id', 'type': 'string'}}, 'required': ['section_id'], 'title': 'read_section_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1078a6480>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_1pglzAhrH4uqpoZhuHNeY1pF', 'output': '### As Xbox Game Studios (2019–present)\\n\\nThe studio rebranded itself on February 5, 2019, as Xbox Game Studios, as to reflect Microsoft\\'s intent to use the Xbox brand to support gaming across all the devices it supports. At [2019](E3)(E3 2019), Xbox Game Studios announced it had acquired [Fine](Double)(Double Fine), and established a new internal studio dedicated to *Age of Empires* headed by Shannon Loftis, bringing their total studio count to fifteen. This studio, later named World\\'s Edge, does not directly develop any games, but oversees efforts from external studios, such as [Entertainment](Relic)(Relic Entertainment), Forgotten Empires and [Media](Tantalus)(Tantalus Media), to assure the series is being developed in the right direction, according to creative director Adam Isgreen.\\n\\nBooty has stated that with studios like Obsidian, Ninja Theory, and Double Fine, which have traditionally supported multiplatform games, they will determine if it makes sense for their future products to be treated as Microsoft-exclusive content for Xbox and Windows computers, or to allow these to be published across multiple platforms. That decision will be based on a \"network effect\", whether having these games on other platforms will better support the franchise and thus worthwhile for Microsoft to help dedicate resources towards it, such as they had with *Minecraft*. Xbox Game Studios has allowed some of the content developed by its studios or that was previously published exclusively for the Xbox and Windows systems to be released on [Nintendo](Nintendo) systems, notably the [Switch](Nintendo)(Nintendo Switch) versions of *[Cuphead](Cuphead)* from Studio MDHR and *[and the Blind Forest](Ori)(Ori and the Blind Forest)* from Moon Studios, and allowing for the titular characters from Rare\\'s *[Banjo-Kazooie](Banjo-Kazooie)* into *[Smash Bros. Ultimate](Super)(Super Smash Bros. Ultimate)*. However, the division stated that these releases were generally \"existing commitments to other platforms\" that they allowed studios to honor, but they otherwise have \"no plans to further expand our exclusive first party games to other consoles.\"\\n\\nNear the end of 2019, with the combined fifteen studios now under Xbox Game Studios, Booty stated that they now had more games than ever to handle, and were likely not going to acquire any additional studios in the near future, stating \"we\\'ve been shifting our focus inside Xbox Game Studios from acquisition and growth, to a phase of execution and delivery\". Additionally, as Microsoft started promotion of its fourth-generation of Xbox, including the [Series X](Xbox)(Xbox Series X), Booty stated that titles developed by Xbox Game Studios in year or two following its release will not be exclusively for the new generation of consoles, but instead will support both Xbox One and the new console, with some games receiving enhanced performance when played on the new console lineup. Booty said that with the large number of studios they had recently acquired, as well as ongoing external partnerships and their [Game Pass](Xbox)(Xbox Game Pass) service, the Studios are able to support a \"breadth of offerings in the portfolio\" designed to attract a large number of players. Further, in an interview in November 2020, Phil Spencer said during an interview regarding the future of the Xbox brand that he intends to put more focus on outputting [RPG](Role-playing video game)s, which had to that point been underserved.\\n\\nMicrosoft and [Media](ZeniMax)(ZeniMax Media) announced on September 21, 2020, that Microsoft planned to acquire ZeniMax and its family of studios, which include [Game Studios](Bethesda)(Bethesda Game Studios), [Studios](Arkane)(Arkane Studios), [Software](id)(id Software), [MachineGames](MachineGames), [Gameworks](Tango)(Tango Gameworks), and [Online Studios](ZeniMax)(ZeniMax Online Studios), for over  in cash. According to Spencer, the ZeniMax acquisition was intended to give Microsoft a large library of games known around the world, and to expand the library of Xbox Game Pass and [XCloud](XCloud). Both U.S. and European Union regulatory agencies approved the acquisition by early March 2021, and the acquisition was formally completed by March 9, 2021. The total price of the deal was $8.1 billion Bethesda Softworks, the primarily publisher for all of ZeniMax\\'s games, remained as an operational unit under Microsoft with the acquisition and retained all its current leadership. With the acquisition, future games from the studios will be exclusive to Xbox consoles, but existing commitments to other platforms (such as Arkane Studios\\' *[Deathloop](Deathloop)* and Tango Gameworks\\' *[Tokyo](Ghostwire:)(Ghostwire: Tokyo)*, which are contractually exclusive to [5](PlayStation)(PlayStation 5)) will still be honored. Spencer stated that Game Pass was also fundamental driver for the acquisition. A preliminary injunction to block the acquisition had been sought in an ongoing class-action lawsuit that ZeniMax faced over *[4](Fallout)(Fallout 4)*, with the plaintiffs in the case arguing that Microsoft could shield ZeniMax\\'s assets from damages should they be found liable after the acquisition. The ZeniMax Board of Directors was dissolved following the Microsoft purchase.\\n\\nOn January 18, 2022, Microsoft announced its intent to acquire [Blizzard](Activision)(Activision Blizzard) in an all-cash deal valued at $68.7 billion. Microsoft stated that this acquisition would make it the third-largest gaming company by revenue, following [Tencent](Tencent) and [Sony](Sony). With the announcement, Microsoft also announced a major change to its corporate structure, with Phil Spencer becoming CEO of the new division Microsoft Gaming, with Matt Booty leading Xbox Game Studios under it. Once approved, Activision Blizzard will then become a subdivision of Microsoft Gaming.\\n', 'type': 'function_call_output'}, output='### As Xbox Game Studios (2019–present)\\n\\nThe studio rebranded itself on February 5, 2019, as Xbox Game Studios, as to reflect Microsoft\\'s intent to use the Xbox brand to support gaming across all the devices it supports. At [2019](E3)(E3 2019), Xbox Game Studios announced it had acquired [Fine](Double)(Double Fine), and established a new internal studio dedicated to *Age of Empires* headed by Shannon Loftis, bringing their total studio count to fifteen. This studio, later named World\\'s Edge, does not directly develop any games, but oversees efforts from external studios, such as [Entertainment](Relic)(Relic Entertainment), Forgotten Empires and [Media](Tantalus)(Tantalus Media), to assure the series is being developed in the right direction, according to creative director Adam Isgreen.\\n\\nBooty has stated that with studios like Obsidian, Ninja Theory, and Double Fine, which have traditionally supported multiplatform games, they will determine if it makes sense for their future products to be treated as Microsoft-exclusive content for Xbox and Windows computers, or to allow these to be published across multiple platforms. That decision will be based on a \"network effect\", whether having these games on other platforms will better support the franchise and thus worthwhile for Microsoft to help dedicate resources towards it, such as they had with *Minecraft*. Xbox Game Studios has allowed some of the content developed by its studios or that was previously published exclusively for the Xbox and Windows systems to be released on [Nintendo](Nintendo) systems, notably the [Switch](Nintendo)(Nintendo Switch) versions of *[Cuphead](Cuphead)* from Studio MDHR and *[and the Blind Forest](Ori)(Ori and the Blind Forest)* from Moon Studios, and allowing for the titular characters from Rare\\'s *[Banjo-Kazooie](Banjo-Kazooie)* into *[Smash Bros. Ultimate](Super)(Super Smash Bros. Ultimate)*. However, the division stated that these releases were generally \"existing commitments to other platforms\" that they allowed studios to honor, but they otherwise have \"no plans to further expand our exclusive first party games to other consoles.\"\\n\\nNear the end of 2019, with the combined fifteen studios now under Xbox Game Studios, Booty stated that they now had more games than ever to handle, and were likely not going to acquire any additional studios in the near future, stating \"we\\'ve been shifting our focus inside Xbox Game Studios from acquisition and growth, to a phase of execution and delivery\". Additionally, as Microsoft started promotion of its fourth-generation of Xbox, including the [Series X](Xbox)(Xbox Series X), Booty stated that titles developed by Xbox Game Studios in year or two following its release will not be exclusively for the new generation of consoles, but instead will support both Xbox One and the new console, with some games receiving enhanced performance when played on the new console lineup. Booty said that with the large number of studios they had recently acquired, as well as ongoing external partnerships and their [Game Pass](Xbox)(Xbox Game Pass) service, the Studios are able to support a \"breadth of offerings in the portfolio\" designed to attract a large number of players. Further, in an interview in November 2020, Phil Spencer said during an interview regarding the future of the Xbox brand that he intends to put more focus on outputting [RPG](Role-playing video game)s, which had to that point been underserved.\\n\\nMicrosoft and [Media](ZeniMax)(ZeniMax Media) announced on September 21, 2020, that Microsoft planned to acquire ZeniMax and its family of studios, which include [Game Studios](Bethesda)(Bethesda Game Studios), [Studios](Arkane)(Arkane Studios), [Software](id)(id Software), [MachineGames](MachineGames), [Gameworks](Tango)(Tango Gameworks), and [Online Studios](ZeniMax)(ZeniMax Online Studios), for over  in cash. According to Spencer, the ZeniMax acquisition was intended to give Microsoft a large library of games known around the world, and to expand the library of Xbox Game Pass and [XCloud](XCloud). Both U.S. and European Union regulatory agencies approved the acquisition by early March 2021, and the acquisition was formally completed by March 9, 2021. The total price of the deal was $8.1 billion Bethesda Softworks, the primarily publisher for all of ZeniMax\\'s games, remained as an operational unit under Microsoft with the acquisition and retained all its current leadership. With the acquisition, future games from the studios will be exclusive to Xbox consoles, but existing commitments to other platforms (such as Arkane Studios\\' *[Deathloop](Deathloop)* and Tango Gameworks\\' *[Tokyo](Ghostwire:)(Ghostwire: Tokyo)*, which are contractually exclusive to [5](PlayStation)(PlayStation 5)) will still be honored. Spencer stated that Game Pass was also fundamental driver for the acquisition. A preliminary injunction to block the acquisition had been sought in an ongoing class-action lawsuit that ZeniMax faced over *[4](Fallout)(Fallout 4)*, with the plaintiffs in the case arguing that Microsoft could shield ZeniMax\\'s assets from damages should they be found liable after the acquisition. The ZeniMax Board of Directors was dissolved following the Microsoft purchase.\\n\\nOn January 18, 2022, Microsoft announced its intent to acquire [Blizzard](Activision)(Activision Blizzard) in an all-cash deal valued at $68.7 billion. Microsoft stated that this acquisition would make it the third-largest gaming company by revenue, following [Tencent](Tencent) and [Sony](Sony). With the announcement, Microsoft also announced a major change to its corporate structure, with Phil Spencer becoming CEO of the new division Microsoft Gaming, with Matt Booty leading Xbox Game Studios under it. Once approved, Activision Blizzard will then become a subdivision of Microsoft Gaming.\\n', type='tool_call_output_item')\n",
      "MessageOutputItem(agent=Agent(name='wiki_agent', instructions=None, prompt=None, handoff_description=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='search_pages_fn', description='Search for top 10 relevant articles using title embedding similarity.', params_json_schema={'properties': {'query': {'description': 'The query to search for.', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'search_pages_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x11dd93d80>, strict_json_schema=True, is_enabled=True), FunctionTool(name='view_sections_fn', description='View the sections of a page.', params_json_schema={'properties': {'page_id': {'description': 'The ID of the page to view.', 'title': 'Page Id', 'type': 'string'}}, 'required': ['page_id'], 'title': 'view_sections_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x177f22f20>, strict_json_schema=True, is_enabled=True), FunctionTool(name='read_section_fn', description='Read a section of a wiki page.', params_json_schema={'properties': {'section_id': {'description': 'The ID of the section to read.', 'title': 'Section Id', 'type': 'string'}}, 'required': ['section_id'], 'title': 'read_section_fn_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1078a6480>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_6851b74cd164819cb8c75390c979ff5d0dbb5dfc2ad9ac0d', content=[ResponseOutputText(annotations=[], text=\"Microsoft's acquisition deal for ZeniMax Media in 2020 was valued at over $8 billion in cash. The total price of the deal was $8.1 billion.\", type='output_text', logprobs=None)], role='assistant', status='completed', type='message'), type='message_output_item')\n"
     ]
    }
   ],
   "source": [
    "for n in result.new_items:\n",
    "    of \n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HF SmolAgents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">What was the value of Microsoft's acquisition deal for ZeniMax Media in 2020?</span>                                   <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIServerModel - gpt-4.1-mini ──────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mWhat was the value of Microsoft's acquisition deal for ZeniMax Media in 2020?\u001b[0m                                   \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIServerModel - gpt-4.1-mini \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">search_results </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> search_pages_tool(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Microsoft acquisition ZeniMax Media 2020\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                           </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(search_results)</span><span style=\"background-color: #272822\">                                                                                          </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34msearch_results\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msearch_pages_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mMicrosoft acquisition ZeniMax Media 2020\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msearch_results\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "[{'page_id': 'xbox_game_studios', 'title': 'Xbox Game Studios'}, {'page_id': 'xbox', 'title': 'Xbox'}, {'page_id': \n",
       "'xbox_series_x_and_series_s', 'title': 'Xbox Series X and Series S'}, {'page_id': 'insomniac_games', 'title': \n",
       "'Insomniac Games'}, {'page_id': 'rockstar_games', 'title': 'Rockstar Games'}, {'page_id': 'frictional_games', \n",
       "'title': 'Frictional Games'}, {'page_id': 'fallout_76', 'title': 'Fallout 76'}, {'page_id': 'gabe_newell', 'title':\n",
       "'Gabe Newell'}, {'page_id': 'microsoft_teams', 'title': 'Microsoft Teams'}, {'page_id': \n",
       "\"assassin's_creed_valhalla\", 'title': \"Assassin's Creed Valhalla\"}]\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "[{'page_id': 'xbox_game_studios', 'title': 'Xbox Game Studios'}, {'page_id': 'xbox', 'title': 'Xbox'}, {'page_id': \n",
       "'xbox_series_x_and_series_s', 'title': 'Xbox Series X and Series S'}, {'page_id': 'insomniac_games', 'title': \n",
       "'Insomniac Games'}, {'page_id': 'rockstar_games', 'title': 'Rockstar Games'}, {'page_id': 'frictional_games', \n",
       "'title': 'Frictional Games'}, {'page_id': 'fallout_76', 'title': 'Fallout 76'}, {'page_id': 'gabe_newell', 'title':\n",
       "'Gabe Newell'}, {'page_id': 'microsoft_teams', 'title': 'Microsoft Teams'}, {'page_id': \n",
       "\"assassin's_creed_valhalla\", 'title': \"Assassin's Creed Valhalla\"}]\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 1.74 seconds| Input tokens: 2,075 | Output tokens: 87]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 1.74 seconds| Input tokens: 2,075 | Output tokens: 87]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">sections </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> view_sections_tool(page_id</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"xbox_game_studios\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                     </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(sections)</span><span style=\"background-color: #272822\">                                                                                                </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34msections\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mview_sections_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpage_id\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mxbox_game_studios\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msections\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "[{'section_id': 'xbox_game_studios:xbox_game_studios', 'section_name': 'Xbox Game Studios'}, {'section_id': \n",
       "'xbox_game_studios:history', 'section_name': 'History'}, {'section_id': \n",
       "'xbox_game_studios:as_microsoft_games_and_microsoft_game_studios_(2000–2011)', 'section_name': 'As Microsoft Games \n",
       "and Microsoft Game Studios (2000–2011)'}, {'section_id': 'xbox_game_studios:as_microsoft_studios_(2011–2019)', \n",
       "'section_name': 'As Microsoft Studios (2011–2019)'}, {'section_id': \n",
       "'xbox_game_studios:shifting_priorities_under_microsoft_ceo_satya_nadella', 'section_name': 'Shifting priorities \n",
       "under Microsoft CEO Satya Nadella'}, {'section_id': 'xbox_game_studios:as_xbox_game_studios_(2019–present)', \n",
       "'section_name': 'As Xbox Game Studios (2019–present)'}, {'section_id': \n",
       "'xbox_game_studios:subsidiaries_and_divisions', 'section_name': 'Subsidiaries and divisions'}, {'section_id': \n",
       "'xbox_game_studios:former', 'section_name': 'Former'}, {'section_id': 'xbox_game_studios:games_published', \n",
       "'section_name': 'Games published'}, {'section_id': 'xbox_game_studios:references', 'section_name': 'References'}, \n",
       "{'section_id': 'xbox_game_studios:external_links', 'section_name': 'External links'}]\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "[{'section_id': 'xbox_game_studios:xbox_game_studios', 'section_name': 'Xbox Game Studios'}, {'section_id': \n",
       "'xbox_game_studios:history', 'section_name': 'History'}, {'section_id': \n",
       "'xbox_game_studios:as_microsoft_games_and_microsoft_game_studios_(2000–2011)', 'section_name': 'As Microsoft Games \n",
       "and Microsoft Game Studios (2000–2011)'}, {'section_id': 'xbox_game_studios:as_microsoft_studios_(2011–2019)', \n",
       "'section_name': 'As Microsoft Studios (2011–2019)'}, {'section_id': \n",
       "'xbox_game_studios:shifting_priorities_under_microsoft_ceo_satya_nadella', 'section_name': 'Shifting priorities \n",
       "under Microsoft CEO Satya Nadella'}, {'section_id': 'xbox_game_studios:as_xbox_game_studios_(2019–present)', \n",
       "'section_name': 'As Xbox Game Studios (2019–present)'}, {'section_id': \n",
       "'xbox_game_studios:subsidiaries_and_divisions', 'section_name': 'Subsidiaries and divisions'}, {'section_id': \n",
       "'xbox_game_studios:former', 'section_name': 'Former'}, {'section_id': 'xbox_game_studios:games_published', \n",
       "'section_name': 'Games published'}, {'section_id': 'xbox_game_studios:references', 'section_name': 'References'}, \n",
       "{'section_id': 'xbox_game_studios:external_links', 'section_name': 'External links'}]\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 1.54 seconds| Input tokens: 4,512 | Output tokens: 171]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 1.54 seconds| Input tokens: 4,512 | Output tokens: 171]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">content </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> read_section_tool(section_id</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"xbox_game_studios:as_xbox_game_studios_(2019–present)\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(content)</span><span style=\"background-color: #272822\">                                                                                                 </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mcontent\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mread_section_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msection_id\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mxbox_game_studios:as_xbox_game_studios_(2019–present)\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcontent\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "### As Xbox Game Studios (2019–present)\n",
       "\n",
       "The studio rebranded itself on February 5, 2019, as Xbox Game Studios, as to reflect Microsoft's intent to use the \n",
       "Xbox brand to support gaming across all the devices it supports. At [2019](E3)(E3 2019), Xbox Game Studios \n",
       "announced it had acquired [Fine](Double)(Double Fine), and established a new internal studio dedicated to *Age of \n",
       "Empires* headed by Shannon Loftis, bringing their total studio count to fifteen. This studio, later named World's \n",
       "Edge, does not directly develop any games, but oversees efforts from external studios, such as \n",
       "[Entertainment](Relic)(Relic Entertainment), Forgotten Empires and [Media](Tantalus)(Tantalus Media), to assure the\n",
       "series is being developed in the right direction, according to creative director Adam Isgreen.\n",
       "\n",
       "Booty has stated that with studios like Obsidian, Ninja Theory, and Double Fine, which have traditionally supported\n",
       "multiplatform games, they will determine if it makes sense for their future products to be treated as \n",
       "Microsoft-exclusive content for Xbox and Windows computers, or to allow these to be published across multiple \n",
       "platforms. That decision will be based on a \"network effect\", whether having these games on other platforms will \n",
       "better support the franchise and thus worthwhile for Microsoft to help dedicate resources towards it, such as they \n",
       "had with *Minecraft*. Xbox Game Studios has allowed some of the content developed by its studios or that was \n",
       "previously published exclusively for the Xbox and Windows systems to be released on [Nintendo](Nintendo) systems, \n",
       "notably the [Switch](Nintendo)(Nintendo Switch) versions of *[Cuphead](Cuphead)* from Studio MDHR and *[and the \n",
       "Blind Forest](Ori)(Ori and the Blind Forest)* from Moon Studios, and allowing for the titular characters from \n",
       "Rare's *[Banjo-Kazooie](Banjo-Kazooie)* into *[Smash Bros. Ultimate](Super)(Super Smash Bros. Ultimate)*. However, \n",
       "the division stated that these releases were generally \"existing commitments to other platforms\" that they allowed \n",
       "studios to honor, but they otherwise have \"no plans to further expand our exclusive first party games to other \n",
       "consoles.\"\n",
       "\n",
       "Near the end of 2019, with the combined fifteen studios now under Xbox Game Studios, Booty stated that they now had\n",
       "more games than ever to handle, and were likely not going to acquire any additional studios in the near future, \n",
       "stating \"we've been shifting our focus inside Xbox Game Studios from acquisition and growth, to a phase of \n",
       "execution and delivery\". Additionally, as Microsoft started promotion of its fourth-generation of Xbox, including \n",
       "the [Series X](Xbox)(Xbox Series X), Booty stated that titles developed by Xbox Game Studios in year or two \n",
       "following its release will not be exclusively for the new generation of consoles, but instead will support both \n",
       "Xbox One and the new console, with some games receiving enhanced performance when played on the new console lineup.\n",
       "Booty said that with the large number of studios they had recently acquired, as well as ongoing external \n",
       "partnerships and their [Game Pass](Xbox)(Xbox Game Pass) service, the Studios are able to support a \"breadth of \n",
       "offerings in the portfolio\" designed to attract a large number of players. Further, in an interview in November \n",
       "2020, Phil Spencer said during an interview regarding the future of the Xbox brand that he intends to put more \n",
       "focus on outputting [RPG](Role-playing video game)s, which had to that point been underserved.\n",
       "\n",
       "Microsoft and [Media](ZeniMax)(ZeniMax Media) announced on September 21, 2020, that Microsoft planned to acquire \n",
       "ZeniMax and its family of studios, which include [Game Studios](Bethesda)(Bethesda Game Studios), \n",
       "[Studios](Arkane)(Arkane Studios), [Software](id)(id Software), [MachineGames](MachineGames), \n",
       "[Gameworks](Tango)(Tango Gameworks), and [Online Studios](ZeniMax)(ZeniMax Online Studios), for over  in cash. \n",
       "According to Spencer, the ZeniMax acquisition was intended to give Microsoft a large library of games known around \n",
       "the world, and to expand the library of Xbox Game Pass and [XCloud](XCloud). Both U.S. and European Union \n",
       "regulatory agencies approved the acquisition by early March 2021, and the acquisition was formally completed by \n",
       "March 9, 2021. The total price of the deal was $8.1 billion Bethesda Softworks, the primarily publisher for all of \n",
       "ZeniMax's games, remained as an operational unit under Microsoft with the acquisition and retained all its current \n",
       "leadership. With the acquisition, future games from the studios will be exclusive to Xbox consoles, but existing \n",
       "commitments to other platforms (such as Arkane Studios' *[Deathloop](Deathloop)* and Tango Gameworks' \n",
       "*[Tokyo](Ghostwire:)(Ghostwire: Tokyo)*, which are contractually exclusive to [5](PlayStation)(PlayStation 5)) will\n",
       "still be honored. Spencer stated that Game Pass was also fundamental driver for the acquisition. A preliminary \n",
       "injunction to block the acquisition had been sought in an ongoing class-action lawsuit that ZeniMax faced over \n",
       "*[4](Fallout)(Fallout 4)*, with the plaintiffs in the case arguing that Microsoft could shield ZeniMax's assets \n",
       "from damages should they be found liable after the acquisition. The ZeniMax Board of Directors was dissolved \n",
       "following the Microsoft purchase.\n",
       "\n",
       "On January 18, 2022, Microsoft announced its intent to acquire [Blizzard](Activision)(Activision Blizzard) in an \n",
       "all-cash deal valued at $68.7 billion. Microsoft stated that this acquisition would make it the third-largest \n",
       "gaming company by revenue, following [Tencent](Tencent) and [Sony](Sony). With the announcement, Microsoft also \n",
       "announced a major change to its corporate structure, with Phil Spencer becoming CEO of the new division Microsoft \n",
       "Gaming, with Matt Booty leading Xbox Game Studios under it. Once approved, Activision Blizzard will then become a \n",
       "subdivision of Microsoft Gaming.\n",
       "\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "### As Xbox Game Studios (2019–present)\n",
       "\n",
       "The studio rebranded itself on February 5, 2019, as Xbox Game Studios, as to reflect Microsoft's intent to use the \n",
       "Xbox brand to support gaming across all the devices it supports. At [2019](E3)(E3 2019), Xbox Game Studios \n",
       "announced it had acquired [Fine](Double)(Double Fine), and established a new internal studio dedicated to *Age of \n",
       "Empires* headed by Shannon Loftis, bringing their total studio count to fifteen. This studio, later named World's \n",
       "Edge, does not directly develop any games, but oversees efforts from external studios, such as \n",
       "[Entertainment](Relic)(Relic Entertainment), Forgotten Empires and [Media](Tantalus)(Tantalus Media), to assure the\n",
       "series is being developed in the right direction, according to creative director Adam Isgreen.\n",
       "\n",
       "Booty has stated that with studios like Obsidian, Ninja Theory, and Double Fine, which have traditionally supported\n",
       "multiplatform games, they will determine if it makes sense for their future products to be treated as \n",
       "Microsoft-exclusive content for Xbox and Windows computers, or to allow these to be published across multiple \n",
       "platforms. That decision will be based on a \"network effect\", whether having these games on other platforms will \n",
       "better support the franchise and thus worthwhile for Microsoft to help dedicate resources towards it, such as they \n",
       "had with *Minecraft*. Xbox Game Studios has allowed some of the content developed by its studios or that was \n",
       "previously published exclusively for the Xbox and Windows systems to be released on [Nintendo](Nintendo) systems, \n",
       "notably the [Switch](Nintendo)(Nintendo Switch) versions of *[Cuphead](Cuphead)* from Studio MDHR and *[and the \n",
       "Blind Forest](Ori)(Ori and the Blind Forest)* from Moon Studios, and allowing for the titular characters from \n",
       "Rare's *[Banjo-Kazooie](Banjo-Kazooie)* into *[Smash Bros. Ultimate](Super)(Super Smash Bros. Ultimate)*. However, \n",
       "the division stated that these releases were generally \"existing commitments to other platforms\" that they allowed \n",
       "studios to honor, but they otherwise have \"no plans to further expand our exclusive first party games to other \n",
       "consoles.\"\n",
       "\n",
       "Near the end of 2019, with the combined fifteen studios now under Xbox Game Studios, Booty stated that they now had\n",
       "more games than ever to handle, and were likely not going to acquire any additional studios in the near future, \n",
       "stating \"we've been shifting our focus inside Xbox Game Studios from acquisition and growth, to a phase of \n",
       "execution and delivery\". Additionally, as Microsoft started promotion of its fourth-generation of Xbox, including \n",
       "the [Series X](Xbox)(Xbox Series X), Booty stated that titles developed by Xbox Game Studios in year or two \n",
       "following its release will not be exclusively for the new generation of consoles, but instead will support both \n",
       "Xbox One and the new console, with some games receiving enhanced performance when played on the new console lineup.\n",
       "Booty said that with the large number of studios they had recently acquired, as well as ongoing external \n",
       "partnerships and their [Game Pass](Xbox)(Xbox Game Pass) service, the Studios are able to support a \"breadth of \n",
       "offerings in the portfolio\" designed to attract a large number of players. Further, in an interview in November \n",
       "2020, Phil Spencer said during an interview regarding the future of the Xbox brand that he intends to put more \n",
       "focus on outputting [RPG](Role-playing video game)s, which had to that point been underserved.\n",
       "\n",
       "Microsoft and [Media](ZeniMax)(ZeniMax Media) announced on September 21, 2020, that Microsoft planned to acquire \n",
       "ZeniMax and its family of studios, which include [Game Studios](Bethesda)(Bethesda Game Studios), \n",
       "[Studios](Arkane)(Arkane Studios), [Software](id)(id Software), [MachineGames](MachineGames), \n",
       "[Gameworks](Tango)(Tango Gameworks), and [Online Studios](ZeniMax)(ZeniMax Online Studios), for over  in cash. \n",
       "According to Spencer, the ZeniMax acquisition was intended to give Microsoft a large library of games known around \n",
       "the world, and to expand the library of Xbox Game Pass and [XCloud](XCloud). Both U.S. and European Union \n",
       "regulatory agencies approved the acquisition by early March 2021, and the acquisition was formally completed by \n",
       "March 9, 2021. The total price of the deal was $8.1 billion Bethesda Softworks, the primarily publisher for all of \n",
       "ZeniMax's games, remained as an operational unit under Microsoft with the acquisition and retained all its current \n",
       "leadership. With the acquisition, future games from the studios will be exclusive to Xbox consoles, but existing \n",
       "commitments to other platforms (such as Arkane Studios' *[Deathloop](Deathloop)* and Tango Gameworks' \n",
       "*[Tokyo](Ghostwire:)(Ghostwire: Tokyo)*, which are contractually exclusive to [5](PlayStation)(PlayStation 5)) will\n",
       "still be honored. Spencer stated that Game Pass was also fundamental driver for the acquisition. A preliminary \n",
       "injunction to block the acquisition had been sought in an ongoing class-action lawsuit that ZeniMax faced over \n",
       "*[4](Fallout)(Fallout 4)*, with the plaintiffs in the case arguing that Microsoft could shield ZeniMax's assets \n",
       "from damages should they be found liable after the acquisition. The ZeniMax Board of Directors was dissolved \n",
       "following the Microsoft purchase.\n",
       "\n",
       "On January 18, 2022, Microsoft announced its intent to acquire [Blizzard](Activision)(Activision Blizzard) in an \n",
       "all-cash deal valued at $68.7 billion. Microsoft stated that this acquisition would make it the third-largest \n",
       "gaming company by revenue, following [Tencent](Tencent) and [Sony](Sony). With the announcement, Microsoft also \n",
       "announced a major change to its corporate structure, with Phil Spencer becoming CEO of the new division Microsoft \n",
       "Gaming, with Matt Booty leading Xbox Game Studios under it. Once approved, Activision Blizzard will then become a \n",
       "subdivision of Microsoft Gaming.\n",
       "\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 3: Duration 1.77 seconds| Input tokens: 7,437 | Output tokens: 261]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 3: Duration 1.77 seconds| Input tokens: 7,437 | Output tokens: 261]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m4\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"$8.1 billion\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                   </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m$8.1 billion\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: $8.1 billion</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: $8.1 billion\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 4: Duration 1.61 seconds| Input tokens: 11,773 | Output tokens: 333]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 4: Duration 1.61 seconds| Input tokens: 11,773 | Output tokens: 333]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'$8.1 billion'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smolagents import OpenAIServerModel, CodeAgent, tool\n",
    "\n",
    "model = OpenAIServerModel(model_id=\"gpt-4.1-mini\")\n",
    "\n",
    "@tool\n",
    "def search_pages_tool(query: str) -> list[dict]:\n",
    "    \"\"\"Search for top 10 relevant articles using title embedding similarity.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search for.\n",
    "    \"\"\"\n",
    "    return search_pages(query)\n",
    "\n",
    "@tool\n",
    "def view_sections_tool(page_id: str) -> list[dict]:\n",
    "    \"\"\"View the sections of a page.\n",
    "    \n",
    "    Args:\n",
    "        page_id (str): The ID of the page to view.\n",
    "    \"\"\"\n",
    "    return view_sections(page_id)\n",
    "\n",
    "@tool\n",
    "def read_section_tool(section_id: str) -> str:\n",
    "    \"\"\"Read a section of a wiki page.\n",
    "    \n",
    "    Args:\n",
    "        section_id (str): The ID of the section to read.\n",
    "    \"\"\"\n",
    "    return read_section(section_id)\n",
    "\n",
    "agent = CodeAgent(\n",
    "    model=model,\n",
    "    tools=[search_pages_tool, view_sections_tool, read_section_tool],\n",
    ")\n",
    "\n",
    "agent.run(\"What was the value of Microsoft's acquisition deal for ZeniMax Media in 2020?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dspy.ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    trajectory={'thought_0': 'I need to find information about Microsoft\\'s acquisition of ZeniMax Media in 2020, specifically the value of the deal. I will start by searching for relevant pages about \"Microsoft acquisition ZeniMax Media 2020\".', 'tool_name_0': 'search_pages', 'tool_args_0': {'query': 'Microsoft acquisition ZeniMax Media 2020'}, 'observation_0': [{'page_id': 'xbox_game_studios', 'title': 'Xbox Game Studios'}, {'page_id': 'xbox', 'title': 'Xbox'}, {'page_id': 'xbox_series_x_and_series_s', 'title': 'Xbox Series X and Series S'}, {'page_id': 'insomniac_games', 'title': 'Insomniac Games'}, {'page_id': 'rockstar_games', 'title': 'Rockstar Games'}, {'page_id': 'frictional_games', 'title': 'Frictional Games'}, {'page_id': 'fallout_76', 'title': 'Fallout 76'}, {'page_id': 'gabe_newell', 'title': 'Gabe Newell'}, {'page_id': 'microsoft_teams', 'title': 'Microsoft Teams'}, {'page_id': \"assassin's_creed_valhalla\", 'title': \"Assassin's Creed Valhalla\"}], 'thought_1': 'The most relevant page for information about Microsoft\\'s acquisition of ZeniMax Media is likely \"Xbox Game Studios\" since ZeniMax Media is a major game publisher and Microsoft acquired it to expand Xbox Game Studios. I will view the sections of the \"xbox_game_studios\" page to find a section that might discuss acquisitions or ZeniMax Media.', 'tool_name_1': 'view_sections', 'tool_args_1': {'page_id': 'xbox_game_studios'}, 'observation_1': [{'section_id': 'xbox_game_studios:xbox_game_studios', 'section_name': 'Xbox Game Studios'}, {'section_id': 'xbox_game_studios:history', 'section_name': 'History'}, {'section_id': 'xbox_game_studios:as_microsoft_games_and_microsoft_game_studios_(2000–2011)', 'section_name': 'As Microsoft Games and Microsoft Game Studios (2000–2011)'}, {'section_id': 'xbox_game_studios:as_microsoft_studios_(2011–2019)', 'section_name': 'As Microsoft Studios (2011–2019)'}, {'section_id': 'xbox_game_studios:shifting_priorities_under_microsoft_ceo_satya_nadella', 'section_name': 'Shifting priorities under Microsoft CEO Satya Nadella'}, {'section_id': 'xbox_game_studios:as_xbox_game_studios_(2019–present)', 'section_name': 'As Xbox Game Studios (2019–present)'}, {'section_id': 'xbox_game_studios:subsidiaries_and_divisions', 'section_name': 'Subsidiaries and divisions'}, {'section_id': 'xbox_game_studios:former', 'section_name': 'Former'}, {'section_id': 'xbox_game_studios:games_published', 'section_name': 'Games published'}, {'section_id': 'xbox_game_studios:references', 'section_name': 'References'}, {'section_id': 'xbox_game_studios:external_links', 'section_name': 'External links'}], 'thought_2': 'The section \"As Xbox Game Studios (2019–present)\" likely covers recent acquisitions including the 2020 acquisition of ZeniMax Media. I will read this section to find the value of the acquisition deal.', 'tool_name_2': 'read_section', 'tool_args_2': {'section_id': 'xbox_game_studios:as_xbox_game_studios_(2019–present)'}, 'observation_2': '### As Xbox Game Studios (2019–present)\\n\\nThe studio rebranded itself on February 5, 2019, as Xbox Game Studios, as to reflect Microsoft\\'s intent to use the Xbox brand to support gaming across all the devices it supports. At [2019](E3)(E3 2019), Xbox Game Studios announced it had acquired [Fine](Double)(Double Fine), and established a new internal studio dedicated to *Age of Empires* headed by Shannon Loftis, bringing their total studio count to fifteen. This studio, later named World\\'s Edge, does not directly develop any games, but oversees efforts from external studios, such as [Entertainment](Relic)(Relic Entertainment), Forgotten Empires and [Media](Tantalus)(Tantalus Media), to assure the series is being developed in the right direction, according to creative director Adam Isgreen.\\n\\nBooty has stated that with studios like Obsidian, Ninja Theory, and Double Fine, which have traditionally supported multiplatform games, they will determine if it makes sense for their future products to be treated as Microsoft-exclusive content for Xbox and Windows computers, or to allow these to be published across multiple platforms. That decision will be based on a \"network effect\", whether having these games on other platforms will better support the franchise and thus worthwhile for Microsoft to help dedicate resources towards it, such as they had with *Minecraft*. Xbox Game Studios has allowed some of the content developed by its studios or that was previously published exclusively for the Xbox and Windows systems to be released on [Nintendo](Nintendo) systems, notably the [Switch](Nintendo)(Nintendo Switch) versions of *[Cuphead](Cuphead)* from Studio MDHR and *[and the Blind Forest](Ori)(Ori and the Blind Forest)* from Moon Studios, and allowing for the titular characters from Rare\\'s *[Banjo-Kazooie](Banjo-Kazooie)* into *[Smash Bros. Ultimate](Super)(Super Smash Bros. Ultimate)*. However, the division stated that these releases were generally \"existing commitments to other platforms\" that they allowed studios to honor, but they otherwise have \"no plans to further expand our exclusive first party games to other consoles.\"\\n\\nNear the end of 2019, with the combined fifteen studios now under Xbox Game Studios, Booty stated that they now had more games than ever to handle, and were likely not going to acquire any additional studios in the near future, stating \"we\\'ve been shifting our focus inside Xbox Game Studios from acquisition and growth, to a phase of execution and delivery\". Additionally, as Microsoft started promotion of its fourth-generation of Xbox, including the [Series X](Xbox)(Xbox Series X), Booty stated that titles developed by Xbox Game Studios in year or two following its release will not be exclusively for the new generation of consoles, but instead will support both Xbox One and the new console, with some games receiving enhanced performance when played on the new console lineup. Booty said that with the large number of studios they had recently acquired, as well as ongoing external partnerships and their [Game Pass](Xbox)(Xbox Game Pass) service, the Studios are able to support a \"breadth of offerings in the portfolio\" designed to attract a large number of players. Further, in an interview in November 2020, Phil Spencer said during an interview regarding the future of the Xbox brand that he intends to put more focus on outputting [RPG](Role-playing video game)s, which had to that point been underserved.\\n\\nMicrosoft and [Media](ZeniMax)(ZeniMax Media) announced on September 21, 2020, that Microsoft planned to acquire ZeniMax and its family of studios, which include [Game Studios](Bethesda)(Bethesda Game Studios), [Studios](Arkane)(Arkane Studios), [Software](id)(id Software), [MachineGames](MachineGames), [Gameworks](Tango)(Tango Gameworks), and [Online Studios](ZeniMax)(ZeniMax Online Studios), for over  in cash. According to Spencer, the ZeniMax acquisition was intended to give Microsoft a large library of games known around the world, and to expand the library of Xbox Game Pass and [XCloud](XCloud). Both U.S. and European Union regulatory agencies approved the acquisition by early March 2021, and the acquisition was formally completed by March 9, 2021. The total price of the deal was $8.1 billion Bethesda Softworks, the primarily publisher for all of ZeniMax\\'s games, remained as an operational unit under Microsoft with the acquisition and retained all its current leadership. With the acquisition, future games from the studios will be exclusive to Xbox consoles, but existing commitments to other platforms (such as Arkane Studios\\' *[Deathloop](Deathloop)* and Tango Gameworks\\' *[Tokyo](Ghostwire:)(Ghostwire: Tokyo)*, which are contractually exclusive to [5](PlayStation)(PlayStation 5)) will still be honored. Spencer stated that Game Pass was also fundamental driver for the acquisition. A preliminary injunction to block the acquisition had been sought in an ongoing class-action lawsuit that ZeniMax faced over *[4](Fallout)(Fallout 4)*, with the plaintiffs in the case arguing that Microsoft could shield ZeniMax\\'s assets from damages should they be found liable after the acquisition. The ZeniMax Board of Directors was dissolved following the Microsoft purchase.\\n\\nOn January 18, 2022, Microsoft announced its intent to acquire [Blizzard](Activision)(Activision Blizzard) in an all-cash deal valued at $68.7 billion. Microsoft stated that this acquisition would make it the third-largest gaming company by revenue, following [Tencent](Tencent) and [Sony](Sony). With the announcement, Microsoft also announced a major change to its corporate structure, with Phil Spencer becoming CEO of the new division Microsoft Gaming, with Matt Booty leading Xbox Game Studios under it. Once approved, Activision Blizzard will then become a subdivision of Microsoft Gaming.\\n', 'thought_3': 'The section confirms that Microsoft acquired ZeniMax Media in a deal valued at $8.1 billion in cash in 2020. I have the exact value of the acquisition deal, so I can now finish and provide the answer.', 'tool_name_3': 'finish', 'tool_args_3': {}, 'observation_3': 'Completed.'},\n",
      "    reasoning='The information found in the \"Xbox Game Studios\" page, specifically in the section \"As Xbox Game Studios (2019–present),\" states that Microsoft announced its plan to acquire ZeniMax Media and its family of studios in 2020. The acquisition deal was valued at $8.1 billion in cash. This confirms the exact value of the acquisition deal for ZeniMax Media by Microsoft in 2020.',\n",
      "    answer=\"Microsoft's acquisition deal for ZeniMax Media in 2020 was valued at $8.1 billion in cash.\"\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM(model=\"gpt-4.1-mini\")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "react = dspy.ReAct(signature=\"question->answer\", tools=[search_pages, view_sections, read_section])\n",
    "\n",
    "result = react(question=\"What was the value of Microsoft's acquisition deal for ZeniMax Media in 2020?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Microsoft's acquisition deal for ZeniMax Media in 2020 was valued at $8.1 billion in cash.\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letta - Stateful LLM Agents\n",
    "\n",
    "- https://docs.letta.com/guides/agents/custom-tools\n",
    "\n",
    "Pros: \n",
    "- First-class support for memory, can locally host memory servers\n",
    "\n",
    "Cons:\n",
    "- Agents aren't always great at state management\n",
    "- Can be hard to eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0588263d7a4958824086a704c8f730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating questions:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 25 total questions\n",
      "\n",
      "1. Q: Which 1956 album by Harry Belafonte was the first LP to sell over one million copies?\n",
      "   A: Calypso\n",
      "   File: Harry Belafonte.md\n",
      "\n",
      "2. Q: What song is Harry Belafonte best known for that includes the signature lyric 'Day-O'?\n",
      "   A: The Banana Boat Song\n",
      "   File: Harry Belafonte.md\n",
      "\n",
      "3. Q: Which civil rights leader was Harry Belafonte a close confidant of during the 1950s and 1960s?\n",
      "   A: Martin Luther King Jr.\n",
      "   File: Harry Belafonte.md\n",
      "\n",
      "4. Q: In which 2018 Spike Lee film did Harry Belafonte make his final screen appearance?\n",
      "   A: BlacKkKlansman\n",
      "   File: Harry Belafonte.md\n",
      "\n",
      "5. Q: What was Harry Belafonte's birth name?\n",
      "   A: Harold George Bellanfanti Jr.\n",
      "   File: Harry Belafonte.md\n",
      "\n",
      "6. Q: In which film series did Linda Hamilton play the character Sarah Connor?\n",
      "   A: Terminator\n",
      "   File: Linda Hamilton.md\n",
      "\n",
      "7. Q: What medical condition did Linda Hamilton publicly discuss having, which affected her marriages?\n",
      "   A: Bipolar disorder\n",
      "   File: Linda Hamilton.md\n",
      "\n",
      "8. Q: Who was Linda Hamilton married to that resulted in a $50 million divorce settlement?\n",
      "   A: James Cameron\n",
      "   File: Linda Hamilton.md\n",
      "\n",
      "9. Q: Which character did Linda Hamilton portray in the television series Beauty and the Beast (1987–1990)?\n",
      "   A: Catherine Chandler\n",
      "   File: Linda Hamilton.md\n",
      "\n",
      "10. Q: Where was Linda Hamilton born?\n",
      "   A: Salisbury, Maryland\n",
      "   File: Linda Hamilton.md\n",
      "\n",
      "11. Q: According to the Gospel of Mark, what type of clothing did John the Baptist wear?\n",
      "   A: Camel's hair\n",
      "   File: John the Baptist.md\n",
      "\n",
      "12. Q: Who ordered the beheading of John the Baptist according to the New Testament?\n",
      "   A: Herod Antipas\n",
      "   File: John the Baptist.md\n",
      "\n",
      "13. Q: In which fortress was John the Baptist executed according to the historian Josephus?\n",
      "   A: Machaerus\n",
      "   File: John the Baptist.md\n",
      "\n",
      "14. Q: What is the traditional feast day of the Nativity of John the Baptist in the Christian liturgical calendar?\n",
      "   A: June 24\n",
      "   File: John the Baptist.md\n",
      "\n",
      "15. Q: Which religious group considers John the Baptist their greatest and final prophet and descends from his original disciples?\n",
      "   A: Mandaeans\n",
      "   File: John the Baptist.md\n",
      "\n",
      "16. Q: Which character's voice did Hank Azaria first perform on The Simpsons?\n",
      "   A: Moe Szyslak\n",
      "   File: Hank Azaria.md\n",
      "\n",
      "17. Q: For which 1996 film did Hank Azaria receive a Screen Actors Guild Award nomination for his supporting role?\n",
      "   A: The Birdcage\n",
      "   File: Hank Azaria.md\n",
      "\n",
      "18. Q: Which voice actor replaced Hank Azaria as the voice of Carl Carlson on The Simpsons after season 32?\n",
      "   A: Alex Désert\n",
      "   File: Hank Azaria.md\n",
      "\n",
      "19. Q: What is the ethnic background of Hank Azaria's grandparents?\n",
      "   A: Sephardic Jews\n",
      "   File: Hank Azaria.md\n",
      "\n",
      "20. Q: In what year did Hank Azaria receive a Doctor of Humane Letters honorary degree from Tufts University?\n",
      "   A: 2016\n",
      "   File: Hank Azaria.md\n",
      "\n",
      "21. Q: Which role earned Richard Thomas an Emmy Award for Best Actor in a Dramatic Series in 1973?\n",
      "   A: John-Boy Walton\n",
      "   File: Richard Thomas _actor.md\n",
      "\n",
      "22. Q: In which Stephen King mini-series did Richard Thomas play the adult Bill Denbrough?\n",
      "   A: It\n",
      "   File: Richard Thomas _actor.md\n",
      "\n",
      "23. Q: What university did Richard Thomas attend before leaving to act full-time in The Waltons?\n",
      "   A: Columbia University\n",
      "   File: Richard Thomas _actor.md\n",
      "\n",
      "24. Q: Who were Richard Thomas's parents and what was their profession?\n",
      "   A: Barbara Fallis and Richard Thomas (dancer), ballet dancers\n",
      "   File: Richard Thomas _actor.md\n",
      "\n",
      "25. Q: Which character did Richard Thomas portray in the FX spy thriller series The Americans?\n",
      "   A: Frank Gaad\n",
      "   File: Richard Thomas _actor.md\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Enable asyncio in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize async OpenAI client\n",
    "openai_client = AsyncOpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Semaphore to limit concurrent requests\n",
    "semaphore = asyncio.Semaphore(3)\n",
    "\n",
    "async def generate_questions_for_file(filepath: str, n_questions: int = 5) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Generate N question-answer pairs for a given wiki file using gpt-4.1.\n",
    "    Returns list of dicts with question, answer, and filename.\n",
    "    \"\"\"\n",
    "    async with semaphore:  # Limit concurrent requests\n",
    "        # Read file content directly\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        filename = os.path.basename(filepath)\n",
    "        \n",
    "        # Prompt for GPT-4.1\n",
    "        prompt = f\"\"\"Given the following article content, generate {n_questions} question-answer pairs.\n",
    "\n",
    "Requirements:\n",
    "- Questions should be one sentence about a specific fact contained in the article\n",
    "    - They should be framed as a general trivia question (the question reader will not see the article OR title OR any other information about the article)\n",
    "    - Questions should be \"fair game\" for advanced pub trivia -- requiring potentially deep obscure knowledge or factual recall or search, but \"self-contained\" (without making reference to the article)\n",
    "- Answers should be just a few words (1-5 words typically)\n",
    "- Return as a JSON object with a \"questions\" list containing dicts with \"question\" and \"answer\" fields\n",
    "\n",
    "Article content:\n",
    "{content[:50000]}\n",
    "\n",
    "Schema: \n",
    "{{\n",
    "    \"questions\": [\n",
    "        {{\n",
    "            \"question\": \"question text\",\n",
    "            \"answer\": \"answer text\"\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Return ONLY the JSON object, no other text.\"\"\"\n",
    "        \n",
    "        # Call GPT-4.1\n",
    "        response = await openai_client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that generates factual question-answer pairs from articles.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        try:\n",
    "            response_content = response.choices[0].message.content\n",
    "            if not response_content:\n",
    "                return []\n",
    "            response_json = json.loads(response_content)\n",
    "            # Handle different possible JSON structures\n",
    "            if isinstance(response_json, list):\n",
    "                qa_pairs = response_json\n",
    "            elif isinstance(response_json, dict):\n",
    "                # Try common keys\n",
    "                qa_pairs = response_json.get('pairs', response_json.get('questions', response_json.get('data', [])))\n",
    "                if not isinstance(qa_pairs, list):\n",
    "                    qa_pairs = []\n",
    "            else:\n",
    "                qa_pairs = []\n",
    "        except json.JSONDecodeError:\n",
    "            return []\n",
    "        \n",
    "        # Add metadata to each pair\n",
    "        results = []\n",
    "        for pair in qa_pairs:\n",
    "            results.append({\n",
    "                \"question\": pair[\"question\"],\n",
    "                \"answer\": pair[\"answer\"],\n",
    "                \"filename\": filename\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "async def generate_random_questions(n_pages: int = 3, questions_per_page: int = 3) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Generate questions for N random wiki pages using parallel processing.\n",
    "    Works directly with files, no database needed.\n",
    "    Returns consolidated list of all question-answer pairs.\n",
    "    \"\"\"\n",
    "    # Get all wiki files directly from directory\n",
    "    wiki_files = [f for f in os.listdir(WIKI_DIR) if f.endswith('.md')]\n",
    "    \n",
    "    # Sample random files\n",
    "    selected_files = random.sample(wiki_files, min(n_pages, len(wiki_files)))\n",
    "    \n",
    "    # Create tasks for parallel processing\n",
    "    tasks = []\n",
    "    for filename in selected_files:\n",
    "        filepath = os.path.join(WIKI_DIR, filename)\n",
    "        task = generate_questions_for_file(filepath, questions_per_page)\n",
    "        tasks.append(task)\n",
    "    \n",
    "    # Execute all tasks in parallel with progress bar\n",
    "    all_results = []\n",
    "    with tqdm(total=len(tasks), desc=\"Generating questions\") as pbar:\n",
    "        for coro in asyncio.as_completed(tasks):\n",
    "            try:\n",
    "                result = await coro\n",
    "                all_results.append(result)\n",
    "                pbar.update(1)\n",
    "            except Exception as e:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "    # Flatten results\n",
    "    all_questions = []\n",
    "    for questions in all_results:\n",
    "        all_questions.extend(questions)\n",
    "\n",
    "    return all_questions\n",
    "\n",
    "# Example usage\n",
    "async def main():\n",
    "    n_pages = 5\n",
    "    questions = await generate_random_questions(n_pages=n_pages, questions_per_page=5)\n",
    "    print(f\"\\nGenerated {len(questions)} total questions\")\n",
    "    \n",
    "    for i, q in enumerate(questions): \n",
    "        print(f\"\\n{i+1}. Q: {q['question']}\")\n",
    "        print(f\"   A: {q['answer']}\")\n",
    "        print(f\"   File: {q['filename']}\")\n",
    "    \n",
    "    return questions\n",
    "\n",
    "# Run the async function\n",
    "questions = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Alex Desert\" == \"Alex Désert\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Judges\n",
    "\n",
    "- Comparing vs. ground truth\n",
    "- Judging semantic properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepEval\n",
    "\n",
    "- https://deepeval.com/docs/metrics-introduction\n",
    "- G-Eval paper: https://arxiv.org/abs/2303.16634"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bf2e9455aa44ab82b4905c2006024c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Metrics: Correctness (GEval) (score: 0.0, threshold: 0.5, strict: False, error: None, reason: The actual output does not match the expected output exactly; it is incomplete and missing the full sentence, including the subject, context, and punctuation, resulting in a failure to meet the exact match criteria.) failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[109]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# for many tests\u001b[39;00m\n\u001b[32m     20\u001b[39m     evaluate(test_cases=[test_case], metrics=[correctness_metric])\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mtest_correctness\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat was the value of Microsoft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms acquisition deal for ZeniMax Media in 2020?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$8.1 billion.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mThe value of Microsoft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms acquisition deal for ZeniMax Media in 2020 was $8.1 billion.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[109]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtest_correctness\u001b[39m\u001b[34m(question, answer, response)\u001b[39m\n\u001b[32m      6\u001b[39m correctness_metric = GEval(\n\u001b[32m      7\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mCorrectness\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4.1-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     threshold=\u001b[32m0.5\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m test_case = LLMTestCase(\n\u001b[32m     14\u001b[39m     \u001b[38;5;28minput\u001b[39m=question,\n\u001b[32m     15\u001b[39m     actual_output=response,\n\u001b[32m     16\u001b[39m     expected_output=answer\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43massert_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcorrectness_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# for many tests\u001b[39;00m\n\u001b[32m     20\u001b[39m evaluate(test_cases=[test_case], metrics=[correctness_metric])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/deepeval/evaluate/evaluate.py:169\u001b[39m, in \u001b[36massert_test\u001b[39m\u001b[34m(test_case, metrics, golden, observed_callback, run_async)\u001b[39m\n\u001b[32m    161\u001b[39m             failed_metrics_data.append(metric_data)\n\u001b[32m    163\u001b[39m failed_metrics_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    164\u001b[39m     [\n\u001b[32m    165\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data.score\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data.threshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, strict: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data.strict_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data.error\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, reason: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data.reason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m metrics_data \u001b[38;5;129;01min\u001b[39;00m failed_metrics_data\n\u001b[32m    167\u001b[39m     ]\n\u001b[32m    168\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMetrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailed_metrics_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAssertionError\u001b[39m: Metrics: Correctness (GEval) (score: 0.0, threshold: 0.5, strict: False, error: None, reason: The actual output does not match the expected output exactly; it is incomplete and missing the full sentence, including the subject, context, and punctuation, resulting in a failure to meet the exact match criteria.) failed."
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate, assert_test\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams # type: ignore\n",
    "from deepeval.metrics import GEval # type: ignore\n",
    "\n",
    "def test_correctness(question, answer, response):\n",
    "    correctness_metric = GEval(\n",
    "        name=\"Correctness\",\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        criteria=\"Determine if the 'actual output' is equal to the 'expected output'.\",\n",
    "        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    "        threshold=0.5\n",
    "    )\n",
    "    test_case = LLMTestCase(\n",
    "        input=question,\n",
    "        actual_output=response,\n",
    "        expected_output=answer\n",
    "    )\n",
    "    assert_test(test_case, [correctness_metric])\n",
    "    # for many tests\n",
    "    evaluate(test_cases=[test_case], metrics=[correctness_metric])\n",
    "\n",
    "test_correctness(\n",
    "    question=\"What was the value of Microsoft's acquisition deal for ZeniMax Media in 2020?\",\n",
    "    response=\"$8.1 billion.\",\n",
    "    answer=\"The value of Microsoft's acquisition deal for ZeniMax Media in 2020 was $8.1 billion.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verifiers (my own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n",
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_description: list[dict]: A list of dicts with page_id and title. (list)\n",
      "return_description: list[dict]: A list of dicts with section_id and section_name. (list)\n",
      "return_description: str: The content of the section. (str)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701619b4f9264337900f107e2ca11205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 16:48:11 - verifiers.rubrics.RubricGroup - INFO - Initialized RubricGroup with 2 rubrics\n"
     ]
    }
   ],
   "source": [
    "import verifiers as vf\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a search agent who has access to the following tools for searching over a set of Wikipedia articles:\n",
    "\n",
    "{tool_descriptions}\n",
    "\n",
    "You may make up to 10 tool calls before giving your final answer.\n",
    "\n",
    "In each turn, respond in the following format:\n",
    "<think>\n",
    "[your thoughts here]\n",
    "</think>\n",
    "<tool>\n",
    "{{\n",
    "    \"name\": \"search_pages\", # name of the tool to call\n",
    "    \"args\": {{\n",
    "        \"query\": \"query\" # arguments to pass to the tool\n",
    "    }}\n",
    "}}\n",
    "</tool>\n",
    "\n",
    "When you have found the answer, respond in the following format:\n",
    "<think>\n",
    "[your thoughts here]\n",
    "</think>\n",
    "<answer>\n",
    "[final answer here]\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "    search_pages,\n",
    "    view_sections,\n",
    "    read_section,\n",
    "]\n",
    "\n",
    "from datasets import load_dataset # type: ignore\n",
    "dataset = load_dataset(\"willcb/wiki-trivia-questions\", split=\"train\").select(range(10))\n",
    "\n",
    "from openai import OpenAI # type: ignore\n",
    "from verifiers.rubrics.judge_rubric import JudgeRubric\n",
    "judge_client = OpenAI()\n",
    "judge_model = \"gpt-4.1-nano\"\n",
    "judge_rubric = JudgeRubric(\n",
    "    judge_client=judge_client,\n",
    "    judge_model=judge_model\n",
    ")\n",
    "\n",
    "vf_env = vf.ToolEnv(\n",
    "    dataset=dataset,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=tools,\n",
    "    max_turns=11,\n",
    ")\n",
    "vf_env.rubric = vf.RubricGroup(rubrics=[judge_rubric, vf_env.rubric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:15:33 - verifiers.envs.ToolEnv - INFO - eval_dataset is not set, falling back to train dataset\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-vRvYgphPIJK9CQHj6eRpmU56 on tokens per min (TPM): Limit 30000, Used 29750, Requested 1046. Please try again in 1.592s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mvf_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m11\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/verifiers/envs/environment.py:557\u001b[39m, in \u001b[36mEnvironment.evaluate\u001b[39m\u001b[34m(self, client, model, sampling_args, num_samples, max_concurrent, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_samples > \u001b[32m0\u001b[39m:\n\u001b[32m    555\u001b[39m     inputs = inputs.select(\u001b[38;5;28mrange\u001b[39m(num_samples))\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_concurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/verifiers/envs/environment.py:349\u001b[39m, in \u001b[36mEnvironment.generate\u001b[39m\u001b[34m(self, inputs, client, model, sampling_args, max_concurrent, score_rollouts, **kwargs)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33minfo\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[32m    348\u001b[39m     results[\u001b[33m'\u001b[39m\u001b[33minfo\u001b[39m\u001b[33m'\u001b[39m] = [{}] * \u001b[38;5;28mlen\u001b[39m(results[\u001b[33m'\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m rollouts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43manswer\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minfo\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_sampling_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mcompletion\u001b[39m\u001b[33m'\u001b[39m] = [rollout[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m rollout \u001b[38;5;129;01min\u001b[39;00m rollouts]\n\u001b[32m    361\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m] = [rollout[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m rollout \u001b[38;5;129;01min\u001b[39;00m rollouts]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/verifiers/envs/environment.py:304\u001b[39m, in \u001b[36mEnvironment.run_rollouts\u001b[39m\u001b[34m(self, client, model, prompts, answers, tasks, infos, sampling_args, max_concurrent, **kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m asyncio.set_event_loop(loop)\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    306\u001b[39m     loop.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/verifiers/envs/environment.py:263\u001b[39m, in \u001b[36mEnvironment._run_all\u001b[39m\u001b[34m(self, client, model, prompts, answers, tasks, infos, sampling_args, max_concurrent, **kwargs)\u001b[39m\n\u001b[32m    258\u001b[39m semaphore = Semaphore(max_concurrent)\n\u001b[32m    259\u001b[39m rollout_tasks = [\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_single(semaphore, client, model, prompt, answer, task, info, sampling_args, **kwargs)\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m prompt, answer, task, info \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(prompts, answers, tasks, infos)\n\u001b[32m    262\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m tqdm_asyncio.gather(\n\u001b[32m    264\u001b[39m     *rollout_tasks,\n\u001b[32m    265\u001b[39m     total=\u001b[38;5;28mlen\u001b[39m(prompts),\n\u001b[32m    266\u001b[39m     desc=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prompts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rollouts\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    267\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:79\u001b[39m, in \u001b[36mtqdm_asyncio.gather\u001b[39m\u001b[34m(cls, loop, timeout, total, *fs, **tqdm_kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m i, \u001b[38;5;28;01mawait\u001b[39;00m f\n\u001b[32m     78\u001b[39m ifs = [wrap_awaitable(i, f) \u001b[38;5;28;01mfor\u001b[39;00m i, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fs)]\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m res = [\u001b[38;5;28;01mawait\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.as_completed(ifs, loop=loop, timeout=timeout,\n\u001b[32m     80\u001b[39m                                          total=total, **tqdm_kwargs)]\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [i \u001b[38;5;28;01mfor\u001b[39;00m _, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(res)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:79\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m i, \u001b[38;5;28;01mawait\u001b[39;00m f\n\u001b[32m     78\u001b[39m ifs = [wrap_awaitable(i, f) \u001b[38;5;28;01mfor\u001b[39;00m i, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fs)]\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m res = [\u001b[38;5;28;01mawait\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.as_completed(ifs, loop=loop, timeout=timeout,\n\u001b[32m     80\u001b[39m                                          total=total, **tqdm_kwargs)]\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [i \u001b[38;5;28;01mfor\u001b[39;00m _, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(res)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:615\u001b[39m, in \u001b[36mas_completed.<locals>._wait_for_one\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    613\u001b[39m     \u001b[38;5;66;03m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.TimeoutError\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:279\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m         result = coro.throw(exc)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    282\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:76\u001b[39m, in \u001b[36mtqdm_asyncio.gather.<locals>.wrap_awaitable\u001b[39m\u001b[34m(i, f)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_awaitable\u001b[39m(i, f):\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m i, \u001b[38;5;28;01mawait\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/verifiers/envs/environment.py:242\u001b[39m, in \u001b[36mEnvironment._run_single\u001b[39m\u001b[34m(self, semaphore, client, model, prompt, answer, task, info, sampling_args, **kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03mRun a rollout for a given prompt.\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mReturns a tuple of (completion, state).\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.to_thread(\u001b[38;5;28mself\u001b[39m.rollout, client, model, prompt, answer, task, info, sampling_args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/asyncio/threads.py:25\u001b[39m, in \u001b[36mto_thread\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m ctx = contextvars.copy_context()\n\u001b[32m     24\u001b[39m func_call = functools.partial(ctx.run, func, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func_call)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/verifiers/envs/multiturn_env.py:54\u001b[39m, in \u001b[36mMultiTurnEnv.rollout\u001b[39m\u001b[34m(self, client, model, prompt, answer, task, info, sampling_args, **kwargs)\u001b[39m\n\u001b[32m     52\u001b[39m     is_completed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_model_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmessage_type\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m has_error = response.startswith(\u001b[33m\"\u001b[39m\u001b[33m[ERROR]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m messages.append({\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: response})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/verifiers/envs/environment.py:183\u001b[39m, in \u001b[36mEnvironment.get_model_response\u001b[39m\u001b[34m(self, prompt, client, model, sampling_args, message_type, sanitize_sampling_args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_type == \u001b[33m'\u001b[39m\u001b[33mchat\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msanitized_args\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;66;03m# Check if generation was truncated due to max_tokens\u001b[39;00m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].finish_reason == \u001b[33m'\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/agents-course/lectures/lec1-agent-patterns/.venv/lib/python3.11/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-vRvYgphPIJK9CQHj6eRpmU56 on tokens per min (TPM): Limit 30000, Used 29750, Requested 1046. Please try again in 1.592s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "results = vf_env.evaluate(\n",
    "    client=OpenAI(),\n",
    "    model=\"gpt-4.1\",\n",
    "    max_turns=11,\n",
    "    max_concurrent=3,\n",
    ")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5692307692307692\n"
     ]
    }
   ],
   "source": [
    "# difflib similarity\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "print(similarity(\"The value of Microsoft's acquisition deal for ZeniMax Media in 2020 was $8.1 billion.\", \"The total value of the deal was $8.1 billion.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6368027313804879\n",
      "0.6368027003436281\n",
      "0.8522878825351152\n"
     ]
    }
   ],
   "source": [
    "# embedding similarity with OAI text-embedding-3-small\n",
    "\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "answer_embedding = client.embeddings.create(\n",
    "    input=\"$8.1B\",\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "response_embedding = client.embeddings.create(\n",
    "    input=\"8.1 billion.\",\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# dot product\n",
    "print(np.dot(answer_embedding.data[0].embedding, response_embedding.data[0].embedding))\n",
    "\n",
    "# cosine similarity -- same if already normalized\n",
    "print(np.dot(answer_embedding.data[0].embedding, response_embedding.data[0].embedding) / (np.linalg.norm(answer_embedding.data[0].embedding) * np.linalg.norm(response_embedding.data[0].embedding)))\n",
    "\n",
    "# euclidean distance\n",
    "print(np.linalg.norm(np.array(answer_embedding.data[0].embedding) - np.array(response_embedding.data[0].embedding)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
